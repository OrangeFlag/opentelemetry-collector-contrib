// Copyright The OpenTelemetry Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/model/pdata"
)

// MetricSettings provides common settings for a particular metric.
type MetricSettings struct {
	Enabled bool `mapstructure:"enabled"`
}

// MetricsSettings provides settings for elasticsearchreceiver metrics.
type MetricsSettings struct {
	ElasticsearchClusterDataNodes            MetricSettings `mapstructure:"elasticsearch.cluster.data_nodes"`
	ElasticsearchClusterNodes                MetricSettings `mapstructure:"elasticsearch.cluster.nodes"`
	ElasticsearchClusterShards               MetricSettings `mapstructure:"elasticsearch.cluster.shards"`
	ElasticsearchNodeCacheEvictions          MetricSettings `mapstructure:"elasticsearch.node.cache.evictions"`
	ElasticsearchNodeCacheMemoryUsage        MetricSettings `mapstructure:"elasticsearch.node.cache.memory.usage"`
	ElasticsearchNodeClusterConnections      MetricSettings `mapstructure:"elasticsearch.node.cluster.connections"`
	ElasticsearchNodeClusterIo               MetricSettings `mapstructure:"elasticsearch.node.cluster.io"`
	ElasticsearchNodeDocuments               MetricSettings `mapstructure:"elasticsearch.node.documents"`
	ElasticsearchNodeFsDiskAvailable         MetricSettings `mapstructure:"elasticsearch.node.fs.disk.available"`
	ElasticsearchNodeFsIoOperations          MetricSettings `mapstructure:"elasticsearch.node.fs.io.operations"`
	ElasticsearchNodeHTTPConnections         MetricSettings `mapstructure:"elasticsearch.node.http.connections"`
	ElasticsearchNodeJvmGcCollectionsCount   MetricSettings `mapstructure:"elasticsearch.node.jvm.gc.collections.count"`
	ElasticsearchNodeJvmGcCollectionsElapsed MetricSettings `mapstructure:"elasticsearch.node.jvm.gc.collections.elapsed"`
	ElasticsearchNodeJvmMemoryHeapMax        MetricSettings `mapstructure:"elasticsearch.node.jvm.memory.heap.max"`
	ElasticsearchNodeJvmMemoryHeapUsed       MetricSettings `mapstructure:"elasticsearch.node.jvm.memory.heap.used"`
	ElasticsearchNodeJvmMemoryNonheapUsed    MetricSettings `mapstructure:"elasticsearch.node.jvm.memory.nonheap.used"`
	ElasticsearchNodeJvmThreadsCount         MetricSettings `mapstructure:"elasticsearch.node.jvm.threads.count"`
	ElasticsearchNodeJvmThreadsPeak          MetricSettings `mapstructure:"elasticsearch.node.jvm.threads.peak"`
	ElasticsearchNodeOpenFiles               MetricSettings `mapstructure:"elasticsearch.node.open_files"`
	ElasticsearchNodeOperationsCompleted     MetricSettings `mapstructure:"elasticsearch.node.operations.completed"`
	ElasticsearchNodeOperationsTime          MetricSettings `mapstructure:"elasticsearch.node.operations.time"`
	ElasticsearchNodeShardsSize              MetricSettings `mapstructure:"elasticsearch.node.shards.size"`
	ElasticsearchNodeThreadPoolTasksFinished MetricSettings `mapstructure:"elasticsearch.node.thread_pool.tasks.finished"`
	ElasticsearchNodeThreadPoolTasksQueued   MetricSettings `mapstructure:"elasticsearch.node.thread_pool.tasks.queued"`
	ElasticsearchNodeThreadPoolThreads       MetricSettings `mapstructure:"elasticsearch.node.thread_pool.threads"`
}

func DefaultMetricsSettings() MetricsSettings {
	return MetricsSettings{
		ElasticsearchClusterDataNodes: MetricSettings{
			Enabled: false,
		},
		ElasticsearchClusterNodes: MetricSettings{
			Enabled: false,
		},
		ElasticsearchClusterShards: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeCacheEvictions: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeCacheMemoryUsage: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeClusterConnections: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeClusterIo: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeDocuments: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeFsDiskAvailable: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeFsIoOperations: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeHTTPConnections: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeJvmGcCollectionsCount: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeJvmGcCollectionsElapsed: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeJvmMemoryHeapMax: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeJvmMemoryHeapUsed: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeJvmMemoryNonheapUsed: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeJvmThreadsCount: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeJvmThreadsPeak: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeOpenFiles: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeOperationsCompleted: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeOperationsTime: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeShardsSize: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeThreadPoolTasksFinished: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeThreadPoolTasksQueued: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeThreadPoolThreads: MetricSettings{
			Enabled: false,
		},
	}
}

// metric holds data for generated metric and keeps track of data points slice capacity.
type metric struct {
	data     pdata.Metric // data buffer for generated metric.
	capacity int          // max observed number of data points added to the metric.
}

func (m *metric) updateCapacity(dpLen int) {
	if dpLen > m.capacity {
		m.capacity = dpLen
	}
}

func newMetric() metric {
	return metric{data: pdata.NewMetric()}
}

type metrics struct {
	elasticsearchClusterDataNodes            metric
	elasticsearchClusterNodes                metric
	elasticsearchClusterShards               metric
	elasticsearchNodeCacheEvictions          metric
	elasticsearchNodeCacheMemoryUsage        metric
	elasticsearchNodeClusterConnections      metric
	elasticsearchNodeClusterIo               metric
	elasticsearchNodeDocuments               metric
	elasticsearchNodeFsDiskAvailable         metric
	elasticsearchNodeFsIoOperations          metric
	elasticsearchNodeHTTPConnections         metric
	elasticsearchNodeJvmGcCollectionsCount   metric
	elasticsearchNodeJvmGcCollectionsElapsed metric
	elasticsearchNodeJvmMemoryHeapMax        metric
	elasticsearchNodeJvmMemoryHeapUsed       metric
	elasticsearchNodeJvmMemoryNonheapUsed    metric
	elasticsearchNodeJvmThreadsCount         metric
	elasticsearchNodeJvmThreadsPeak          metric
	elasticsearchNodeOpenFiles               metric
	elasticsearchNodeOperationsCompleted     metric
	elasticsearchNodeOperationsTime          metric
	elasticsearchNodeShardsSize              metric
	elasticsearchNodeThreadPoolTasksFinished metric
	elasticsearchNodeThreadPoolTasksQueued   metric
	elasticsearchNodeThreadPoolThreads       metric
}

func newMetrics(config MetricsSettings) metrics {
	ms := metrics{}
	if config.ElasticsearchClusterDataNodes.Enabled {
		ms.elasticsearchClusterDataNodes = newMetric()
	}
	if config.ElasticsearchClusterNodes.Enabled {
		ms.elasticsearchClusterNodes = newMetric()
	}
	if config.ElasticsearchClusterShards.Enabled {
		ms.elasticsearchClusterShards = newMetric()
	}
	if config.ElasticsearchNodeCacheEvictions.Enabled {
		ms.elasticsearchNodeCacheEvictions = newMetric()
	}
	if config.ElasticsearchNodeCacheMemoryUsage.Enabled {
		ms.elasticsearchNodeCacheMemoryUsage = newMetric()
	}
	if config.ElasticsearchNodeClusterConnections.Enabled {
		ms.elasticsearchNodeClusterConnections = newMetric()
	}
	if config.ElasticsearchNodeClusterIo.Enabled {
		ms.elasticsearchNodeClusterIo = newMetric()
	}
	if config.ElasticsearchNodeDocuments.Enabled {
		ms.elasticsearchNodeDocuments = newMetric()
	}
	if config.ElasticsearchNodeFsDiskAvailable.Enabled {
		ms.elasticsearchNodeFsDiskAvailable = newMetric()
	}
	if config.ElasticsearchNodeFsIoOperations.Enabled {
		ms.elasticsearchNodeFsIoOperations = newMetric()
	}
	if config.ElasticsearchNodeHTTPConnections.Enabled {
		ms.elasticsearchNodeHTTPConnections = newMetric()
	}
	if config.ElasticsearchNodeJvmGcCollectionsCount.Enabled {
		ms.elasticsearchNodeJvmGcCollectionsCount = newMetric()
	}
	if config.ElasticsearchNodeJvmGcCollectionsElapsed.Enabled {
		ms.elasticsearchNodeJvmGcCollectionsElapsed = newMetric()
	}
	if config.ElasticsearchNodeJvmMemoryHeapMax.Enabled {
		ms.elasticsearchNodeJvmMemoryHeapMax = newMetric()
	}
	if config.ElasticsearchNodeJvmMemoryHeapUsed.Enabled {
		ms.elasticsearchNodeJvmMemoryHeapUsed = newMetric()
	}
	if config.ElasticsearchNodeJvmMemoryNonheapUsed.Enabled {
		ms.elasticsearchNodeJvmMemoryNonheapUsed = newMetric()
	}
	if config.ElasticsearchNodeJvmThreadsCount.Enabled {
		ms.elasticsearchNodeJvmThreadsCount = newMetric()
	}
	if config.ElasticsearchNodeJvmThreadsPeak.Enabled {
		ms.elasticsearchNodeJvmThreadsPeak = newMetric()
	}
	if config.ElasticsearchNodeOpenFiles.Enabled {
		ms.elasticsearchNodeOpenFiles = newMetric()
	}
	if config.ElasticsearchNodeOperationsCompleted.Enabled {
		ms.elasticsearchNodeOperationsCompleted = newMetric()
	}
	if config.ElasticsearchNodeOperationsTime.Enabled {
		ms.elasticsearchNodeOperationsTime = newMetric()
	}
	if config.ElasticsearchNodeShardsSize.Enabled {
		ms.elasticsearchNodeShardsSize = newMetric()
	}
	if config.ElasticsearchNodeThreadPoolTasksFinished.Enabled {
		ms.elasticsearchNodeThreadPoolTasksFinished = newMetric()
	}
	if config.ElasticsearchNodeThreadPoolTasksQueued.Enabled {
		ms.elasticsearchNodeThreadPoolTasksQueued = newMetric()
	}
	if config.ElasticsearchNodeThreadPoolThreads.Enabled {
		ms.elasticsearchNodeThreadPoolThreads = newMetric()
	}
	return ms
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user configuration.
type MetricsBuilder struct {
	config    MetricsSettings
	startTime pdata.Timestamp
	metrics   metrics
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pdata.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(config MetricsSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:    config,
		startTime: pdata.NewTimestampFromTime(time.Now()),
		metrics:   newMetrics(config),
	}

	for _, op := range options {
		op(mb)
	}

	mb.initMetrics()
	return mb
}

// Emit appends generated metrics to a pdata.MetricsSlice and updates the internal state to be ready for recording
// another set of data points. This function will be doing all transformations required to produce metric representation
// defined in metadata and user configuration, e.g. delta/cumulative translation.
func (mb *MetricsBuilder) Emit(metrics pdata.MetricSlice) {
	if mb.config.ElasticsearchClusterDataNodes.Enabled && mb.metrics.elasticsearchClusterDataNodes.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchClusterDataNodes.updateCapacity(mb.metrics.elasticsearchClusterDataNodes.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchClusterDataNodes.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchClusterNodes.Enabled && mb.metrics.elasticsearchClusterNodes.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchClusterNodes.updateCapacity(mb.metrics.elasticsearchClusterNodes.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchClusterNodes.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchClusterShards.Enabled && mb.metrics.elasticsearchClusterShards.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchClusterShards.updateCapacity(mb.metrics.elasticsearchClusterShards.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchClusterShards.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeCacheEvictions.Enabled && mb.metrics.elasticsearchNodeCacheEvictions.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeCacheEvictions.updateCapacity(mb.metrics.elasticsearchNodeCacheEvictions.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeCacheEvictions.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeCacheMemoryUsage.Enabled && mb.metrics.elasticsearchNodeCacheMemoryUsage.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeCacheMemoryUsage.updateCapacity(mb.metrics.elasticsearchNodeCacheMemoryUsage.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeCacheMemoryUsage.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeClusterConnections.Enabled && mb.metrics.elasticsearchNodeClusterConnections.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeClusterConnections.updateCapacity(mb.metrics.elasticsearchNodeClusterConnections.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeClusterConnections.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeClusterIo.Enabled && mb.metrics.elasticsearchNodeClusterIo.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeClusterIo.updateCapacity(mb.metrics.elasticsearchNodeClusterIo.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeClusterIo.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeDocuments.Enabled && mb.metrics.elasticsearchNodeDocuments.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeDocuments.updateCapacity(mb.metrics.elasticsearchNodeDocuments.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeDocuments.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeFsDiskAvailable.Enabled && mb.metrics.elasticsearchNodeFsDiskAvailable.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeFsDiskAvailable.updateCapacity(mb.metrics.elasticsearchNodeFsDiskAvailable.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeFsDiskAvailable.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeFsIoOperations.Enabled && mb.metrics.elasticsearchNodeFsIoOperations.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeFsIoOperations.updateCapacity(mb.metrics.elasticsearchNodeFsIoOperations.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeFsIoOperations.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeHTTPConnections.Enabled && mb.metrics.elasticsearchNodeHTTPConnections.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeHTTPConnections.updateCapacity(mb.metrics.elasticsearchNodeHTTPConnections.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeHTTPConnections.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeJvmGcCollectionsCount.Enabled && mb.metrics.elasticsearchNodeJvmGcCollectionsCount.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeJvmGcCollectionsCount.updateCapacity(mb.metrics.elasticsearchNodeJvmGcCollectionsCount.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeJvmGcCollectionsCount.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeJvmGcCollectionsElapsed.Enabled && mb.metrics.elasticsearchNodeJvmGcCollectionsElapsed.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeJvmGcCollectionsElapsed.updateCapacity(mb.metrics.elasticsearchNodeJvmGcCollectionsElapsed.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeJvmGcCollectionsElapsed.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeJvmMemoryHeapMax.Enabled && mb.metrics.elasticsearchNodeJvmMemoryHeapMax.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeJvmMemoryHeapMax.updateCapacity(mb.metrics.elasticsearchNodeJvmMemoryHeapMax.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeJvmMemoryHeapMax.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeJvmMemoryHeapUsed.Enabled && mb.metrics.elasticsearchNodeJvmMemoryHeapUsed.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeJvmMemoryHeapUsed.updateCapacity(mb.metrics.elasticsearchNodeJvmMemoryHeapUsed.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeJvmMemoryHeapUsed.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeJvmMemoryNonheapUsed.Enabled && mb.metrics.elasticsearchNodeJvmMemoryNonheapUsed.data.Gauge().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeJvmMemoryNonheapUsed.updateCapacity(mb.metrics.elasticsearchNodeJvmMemoryNonheapUsed.data.Gauge().DataPoints().Len())
		mb.metrics.elasticsearchNodeJvmMemoryNonheapUsed.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeJvmThreadsCount.Enabled && mb.metrics.elasticsearchNodeJvmThreadsCount.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeJvmThreadsCount.updateCapacity(mb.metrics.elasticsearchNodeJvmThreadsCount.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeJvmThreadsCount.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeJvmThreadsPeak.Enabled && mb.metrics.elasticsearchNodeJvmThreadsPeak.data.Gauge().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeJvmThreadsPeak.updateCapacity(mb.metrics.elasticsearchNodeJvmThreadsPeak.data.Gauge().DataPoints().Len())
		mb.metrics.elasticsearchNodeJvmThreadsPeak.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeOpenFiles.Enabled && mb.metrics.elasticsearchNodeOpenFiles.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeOpenFiles.updateCapacity(mb.metrics.elasticsearchNodeOpenFiles.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeOpenFiles.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeOperationsCompleted.Enabled && mb.metrics.elasticsearchNodeOperationsCompleted.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeOperationsCompleted.updateCapacity(mb.metrics.elasticsearchNodeOperationsCompleted.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeOperationsCompleted.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeOperationsTime.Enabled && mb.metrics.elasticsearchNodeOperationsTime.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeOperationsTime.updateCapacity(mb.metrics.elasticsearchNodeOperationsTime.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeOperationsTime.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeShardsSize.Enabled && mb.metrics.elasticsearchNodeShardsSize.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeShardsSize.updateCapacity(mb.metrics.elasticsearchNodeShardsSize.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeShardsSize.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeThreadPoolTasksFinished.Enabled && mb.metrics.elasticsearchNodeThreadPoolTasksFinished.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeThreadPoolTasksFinished.updateCapacity(mb.metrics.elasticsearchNodeThreadPoolTasksFinished.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeThreadPoolTasksFinished.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeThreadPoolTasksQueued.Enabled && mb.metrics.elasticsearchNodeThreadPoolTasksQueued.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeThreadPoolTasksQueued.updateCapacity(mb.metrics.elasticsearchNodeThreadPoolTasksQueued.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeThreadPoolTasksQueued.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeThreadPoolThreads.Enabled && mb.metrics.elasticsearchNodeThreadPoolThreads.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeThreadPoolThreads.updateCapacity(mb.metrics.elasticsearchNodeThreadPoolThreads.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeThreadPoolThreads.data.MoveTo(metrics.AppendEmpty())
	}

	// Reset metric data points collection.
	mb.initMetrics()
}

// initElasticsearchClusterDataNodesMetric builds new elasticsearch.cluster.data_nodes metric.
func (mb *MetricsBuilder) initElasticsearchClusterDataNodesMetric() {
	metric := mb.metrics.elasticsearchClusterDataNodes
	metric.data.SetName("elasticsearch.cluster.data_nodes")
	metric.data.SetDescription("The number of data nodes in the cluster.")
	metric.data.SetUnit("{nodes}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchClusterNodesMetric builds new elasticsearch.cluster.nodes metric.
func (mb *MetricsBuilder) initElasticsearchClusterNodesMetric() {
	metric := mb.metrics.elasticsearchClusterNodes
	metric.data.SetName("elasticsearch.cluster.nodes")
	metric.data.SetDescription("The total number of nodes in the cluster.")
	metric.data.SetUnit("{nodes}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchClusterShardsMetric builds new elasticsearch.cluster.shards metric.
func (mb *MetricsBuilder) initElasticsearchClusterShardsMetric() {
	metric := mb.metrics.elasticsearchClusterShards
	metric.data.SetName("elasticsearch.cluster.shards")
	metric.data.SetDescription("The number of shards in the cluster.")
	metric.data.SetUnit("{shards}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeCacheEvictionsMetric builds new elasticsearch.node.cache.evictions metric.
func (mb *MetricsBuilder) initElasticsearchNodeCacheEvictionsMetric() {
	metric := mb.metrics.elasticsearchNodeCacheEvictions
	metric.data.SetName("elasticsearch.node.cache.evictions")
	metric.data.SetDescription("The number of evictions from the cache.")
	metric.data.SetUnit("{evictions}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(true)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeCacheMemoryUsageMetric builds new elasticsearch.node.cache.memory.usage metric.
func (mb *MetricsBuilder) initElasticsearchNodeCacheMemoryUsageMetric() {
	metric := mb.metrics.elasticsearchNodeCacheMemoryUsage
	metric.data.SetName("elasticsearch.node.cache.memory.usage")
	metric.data.SetDescription("The size in bytes of the cache.")
	metric.data.SetUnit("By")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeClusterConnectionsMetric builds new elasticsearch.node.cluster.connections metric.
func (mb *MetricsBuilder) initElasticsearchNodeClusterConnectionsMetric() {
	metric := mb.metrics.elasticsearchNodeClusterConnections
	metric.data.SetName("elasticsearch.node.cluster.connections")
	metric.data.SetDescription("Number of open tcp connections for internal cluster communication.")
	metric.data.SetUnit("{connections}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchNodeClusterIoMetric builds new elasticsearch.node.cluster.io metric.
func (mb *MetricsBuilder) initElasticsearchNodeClusterIoMetric() {
	metric := mb.metrics.elasticsearchNodeClusterIo
	metric.data.SetName("elasticsearch.node.cluster.io")
	metric.data.SetDescription("Number of bytes sent and received on the network for internal cluster communication.")
	metric.data.SetUnit("By")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(true)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeDocumentsMetric builds new elasticsearch.node.documents metric.
func (mb *MetricsBuilder) initElasticsearchNodeDocumentsMetric() {
	metric := mb.metrics.elasticsearchNodeDocuments
	metric.data.SetName("elasticsearch.node.documents")
	metric.data.SetDescription("The number of documents on the node.")
	metric.data.SetUnit("{documents}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeFsDiskAvailableMetric builds new elasticsearch.node.fs.disk.available metric.
func (mb *MetricsBuilder) initElasticsearchNodeFsDiskAvailableMetric() {
	metric := mb.metrics.elasticsearchNodeFsDiskAvailable
	metric.data.SetName("elasticsearch.node.fs.disk.available")
	metric.data.SetDescription("The amount of disk space available across all file stores for this node.")
	metric.data.SetUnit("By")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchNodeFsIoOperationsMetric builds new elasticsearch.node.fs.io.operations metric.
func (mb *MetricsBuilder) initElasticsearchNodeFsIoOperationsMetric() {
	metric := mb.metrics.elasticsearchNodeFsIoOperations
	metric.data.SetName("elasticsearch.node.fs.io.operations")
	metric.data.SetDescription("The number of io operations completed across all file stores since starting Elasticsearch. Only available on Linux nodes.")
	metric.data.SetUnit("{operations}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(true)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeHTTPConnectionsMetric builds new elasticsearch.node.http.connections metric.
func (mb *MetricsBuilder) initElasticsearchNodeHTTPConnectionsMetric() {
	metric := mb.metrics.elasticsearchNodeHTTPConnections
	metric.data.SetName("elasticsearch.node.http.connections")
	metric.data.SetDescription("Number of HTTP connections to the node.")
	metric.data.SetUnit("{connections}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchNodeJvmGcCollectionsCountMetric builds new elasticsearch.node.jvm.gc.collections.count metric.
func (mb *MetricsBuilder) initElasticsearchNodeJvmGcCollectionsCountMetric() {
	metric := mb.metrics.elasticsearchNodeJvmGcCollectionsCount
	metric.data.SetName("elasticsearch.node.jvm.gc.collections.count")
	metric.data.SetDescription("The number of garbage collections performed by the JVM.")
	metric.data.SetUnit("{collections}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(true)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeJvmGcCollectionsElapsedMetric builds new elasticsearch.node.jvm.gc.collections.elapsed metric.
func (mb *MetricsBuilder) initElasticsearchNodeJvmGcCollectionsElapsedMetric() {
	metric := mb.metrics.elasticsearchNodeJvmGcCollectionsElapsed
	metric.data.SetName("elasticsearch.node.jvm.gc.collections.elapsed")
	metric.data.SetDescription("The total time spent by the JVM running the GC.")
	metric.data.SetUnit("ms")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(true)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeJvmMemoryHeapMaxMetric builds new elasticsearch.node.jvm.memory.heap.max metric.
func (mb *MetricsBuilder) initElasticsearchNodeJvmMemoryHeapMaxMetric() {
	metric := mb.metrics.elasticsearchNodeJvmMemoryHeapMax
	metric.data.SetName("elasticsearch.node.jvm.memory.heap.max")
	metric.data.SetDescription("The max memory used by the JVM.")
	metric.data.SetUnit("By")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchNodeJvmMemoryHeapUsedMetric builds new elasticsearch.node.jvm.memory.heap.used metric.
func (mb *MetricsBuilder) initElasticsearchNodeJvmMemoryHeapUsedMetric() {
	metric := mb.metrics.elasticsearchNodeJvmMemoryHeapUsed
	metric.data.SetName("elasticsearch.node.jvm.memory.heap.used")
	metric.data.SetDescription("The current heap memory in use by the JVM.")
	metric.data.SetUnit("By")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchNodeJvmMemoryNonheapUsedMetric builds new elasticsearch.node.jvm.memory.nonheap.used metric.
func (mb *MetricsBuilder) initElasticsearchNodeJvmMemoryNonheapUsedMetric() {
	metric := mb.metrics.elasticsearchNodeJvmMemoryNonheapUsed
	metric.data.SetName("elasticsearch.node.jvm.memory.nonheap.used")
	metric.data.SetDescription("The current nonheap memory in use by the JVM.")
	metric.data.SetUnit("By")
	metric.data.SetDataType(pdata.MetricDataTypeGauge)
}

// initElasticsearchNodeJvmThreadsCountMetric builds new elasticsearch.node.jvm.threads.count metric.
func (mb *MetricsBuilder) initElasticsearchNodeJvmThreadsCountMetric() {
	metric := mb.metrics.elasticsearchNodeJvmThreadsCount
	metric.data.SetName("elasticsearch.node.jvm.threads.count")
	metric.data.SetDescription("The number of open threads in the node's JVM process.")
	metric.data.SetUnit("{threads}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchNodeJvmThreadsPeakMetric builds new elasticsearch.node.jvm.threads.peak metric.
func (mb *MetricsBuilder) initElasticsearchNodeJvmThreadsPeakMetric() {
	metric := mb.metrics.elasticsearchNodeJvmThreadsPeak
	metric.data.SetName("elasticsearch.node.jvm.threads.peak")
	metric.data.SetDescription("The maximum number of concurrently running threads in the node's JVM process.")
	metric.data.SetUnit("{threads}")
	metric.data.SetDataType(pdata.MetricDataTypeGauge)
}

// initElasticsearchNodeOpenFilesMetric builds new elasticsearch.node.open_files metric.
func (mb *MetricsBuilder) initElasticsearchNodeOpenFilesMetric() {
	metric := mb.metrics.elasticsearchNodeOpenFiles
	metric.data.SetName("elasticsearch.node.open_files")
	metric.data.SetDescription("The number of open file descriptors held by the node.")
	metric.data.SetUnit("{files}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchNodeOperationsCompletedMetric builds new elasticsearch.node.operations.completed metric.
func (mb *MetricsBuilder) initElasticsearchNodeOperationsCompletedMetric() {
	metric := mb.metrics.elasticsearchNodeOperationsCompleted
	metric.data.SetName("elasticsearch.node.operations.completed")
	metric.data.SetDescription("Number of operations completed.")
	metric.data.SetUnit("{operations}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(true)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeOperationsTimeMetric builds new elasticsearch.node.operations.time metric.
func (mb *MetricsBuilder) initElasticsearchNodeOperationsTimeMetric() {
	metric := mb.metrics.elasticsearchNodeOperationsTime
	metric.data.SetName("elasticsearch.node.operations.time")
	metric.data.SetDescription("Time spent on operations.")
	metric.data.SetUnit("ms")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(true)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeShardsSizeMetric builds new elasticsearch.node.shards.size metric.
func (mb *MetricsBuilder) initElasticsearchNodeShardsSizeMetric() {
	metric := mb.metrics.elasticsearchNodeShardsSize
	metric.data.SetName("elasticsearch.node.shards.size")
	metric.data.SetDescription("The total size of the shards assigned to this node.")
	metric.data.SetUnit("By")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchNodeThreadPoolTasksFinishedMetric builds new elasticsearch.node.thread_pool.tasks.finished metric.
func (mb *MetricsBuilder) initElasticsearchNodeThreadPoolTasksFinishedMetric() {
	metric := mb.metrics.elasticsearchNodeThreadPoolTasksFinished
	metric.data.SetName("elasticsearch.node.thread_pool.tasks.finished")
	metric.data.SetDescription("The number of tasks finished by the thread pool.")
	metric.data.SetUnit("{tasks}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(true)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeThreadPoolTasksQueuedMetric builds new elasticsearch.node.thread_pool.tasks.queued metric.
func (mb *MetricsBuilder) initElasticsearchNodeThreadPoolTasksQueuedMetric() {
	metric := mb.metrics.elasticsearchNodeThreadPoolTasksQueued
	metric.data.SetName("elasticsearch.node.thread_pool.tasks.queued")
	metric.data.SetDescription("The number of queued tasks in the thread pool.")
	metric.data.SetUnit("{tasks}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeThreadPoolThreadsMetric builds new elasticsearch.node.thread_pool.threads metric.
func (mb *MetricsBuilder) initElasticsearchNodeThreadPoolThreadsMetric() {
	metric := mb.metrics.elasticsearchNodeThreadPoolThreads
	metric.data.SetName("elasticsearch.node.thread_pool.threads")
	metric.data.SetDescription("The number of threads in the thread pool.")
	metric.data.SetUnit("{threads}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initMetrics initializes metrics.
func (mb *MetricsBuilder) initMetrics() {
	if mb.config.ElasticsearchClusterDataNodes.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchClusterDataNodesMetric()
	}
	if mb.config.ElasticsearchClusterNodes.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchClusterNodesMetric()
	}
	if mb.config.ElasticsearchClusterShards.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchClusterShardsMetric()
	}
	if mb.config.ElasticsearchNodeCacheEvictions.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeCacheEvictionsMetric()
	}
	if mb.config.ElasticsearchNodeCacheMemoryUsage.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeCacheMemoryUsageMetric()
	}
	if mb.config.ElasticsearchNodeClusterConnections.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeClusterConnectionsMetric()
	}
	if mb.config.ElasticsearchNodeClusterIo.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeClusterIoMetric()
	}
	if mb.config.ElasticsearchNodeDocuments.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeDocumentsMetric()
	}
	if mb.config.ElasticsearchNodeFsDiskAvailable.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeFsDiskAvailableMetric()
	}
	if mb.config.ElasticsearchNodeFsIoOperations.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeFsIoOperationsMetric()
	}
	if mb.config.ElasticsearchNodeHTTPConnections.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeHTTPConnectionsMetric()
	}
	if mb.config.ElasticsearchNodeJvmGcCollectionsCount.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeJvmGcCollectionsCountMetric()
	}
	if mb.config.ElasticsearchNodeJvmGcCollectionsElapsed.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeJvmGcCollectionsElapsedMetric()
	}
	if mb.config.ElasticsearchNodeJvmMemoryHeapMax.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeJvmMemoryHeapMaxMetric()
	}
	if mb.config.ElasticsearchNodeJvmMemoryHeapUsed.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeJvmMemoryHeapUsedMetric()
	}
	if mb.config.ElasticsearchNodeJvmMemoryNonheapUsed.Enabled {
		// TODO: Use metric.data.Gauge().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeJvmMemoryNonheapUsedMetric()
	}
	if mb.config.ElasticsearchNodeJvmThreadsCount.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeJvmThreadsCountMetric()
	}
	if mb.config.ElasticsearchNodeJvmThreadsPeak.Enabled {
		// TODO: Use metric.data.Gauge().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeJvmThreadsPeakMetric()
	}
	if mb.config.ElasticsearchNodeOpenFiles.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeOpenFilesMetric()
	}
	if mb.config.ElasticsearchNodeOperationsCompleted.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeOperationsCompletedMetric()
	}
	if mb.config.ElasticsearchNodeOperationsTime.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeOperationsTimeMetric()
	}
	if mb.config.ElasticsearchNodeShardsSize.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeShardsSizeMetric()
	}
	if mb.config.ElasticsearchNodeThreadPoolTasksFinished.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeThreadPoolTasksFinishedMetric()
	}
	if mb.config.ElasticsearchNodeThreadPoolTasksQueued.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeThreadPoolTasksQueuedMetric()
	}
	if mb.config.ElasticsearchNodeThreadPoolThreads.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeThreadPoolThreadsMetric()
	}
}

// RecordElasticsearchClusterDataNodesDataPoint adds a data point to elasticsearch.cluster.data_nodes metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchClusterDataNodesDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchClusterDataNodes.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchClusterDataNodes.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchClusterNodesDataPoint adds a data point to elasticsearch.cluster.nodes metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchClusterNodesDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchClusterNodes.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchClusterNodes.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchClusterShardsDataPoint adds a data point to elasticsearch.cluster.shards metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchClusterShardsDataPoint(ts pdata.Timestamp, val int64, shard_typeAttributeValue string) {
	if !mb.config.ElasticsearchClusterShards.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchClusterShards.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.ShardType, pdata.NewAttributeValueString(shard_typeAttributeValue))
}

// RecordElasticsearchNodeCacheEvictionsDataPoint adds a data point to elasticsearch.node.cache.evictions metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeCacheEvictionsDataPoint(ts pdata.Timestamp, val int64, cache_nameAttributeValue string) {
	if !mb.config.ElasticsearchNodeCacheEvictions.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeCacheEvictions.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.CacheName, pdata.NewAttributeValueString(cache_nameAttributeValue))
}

// RecordElasticsearchNodeCacheMemoryUsageDataPoint adds a data point to elasticsearch.node.cache.memory.usage metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeCacheMemoryUsageDataPoint(ts pdata.Timestamp, val int64, cache_nameAttributeValue string) {
	if !mb.config.ElasticsearchNodeCacheMemoryUsage.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeCacheMemoryUsage.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.CacheName, pdata.NewAttributeValueString(cache_nameAttributeValue))
}

// RecordElasticsearchNodeClusterConnectionsDataPoint adds a data point to elasticsearch.node.cluster.connections metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeClusterConnectionsDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeClusterConnections.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeClusterConnections.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeClusterIoDataPoint adds a data point to elasticsearch.node.cluster.io metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeClusterIoDataPoint(ts pdata.Timestamp, val int64, directionAttributeValue string) {
	if !mb.config.ElasticsearchNodeClusterIo.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeClusterIo.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Direction, pdata.NewAttributeValueString(directionAttributeValue))
}

// RecordElasticsearchNodeDocumentsDataPoint adds a data point to elasticsearch.node.documents metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeDocumentsDataPoint(ts pdata.Timestamp, val int64, document_stateAttributeValue string) {
	if !mb.config.ElasticsearchNodeDocuments.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeDocuments.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.DocumentState, pdata.NewAttributeValueString(document_stateAttributeValue))
}

// RecordElasticsearchNodeFsDiskAvailableDataPoint adds a data point to elasticsearch.node.fs.disk.available metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeFsDiskAvailableDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeFsDiskAvailable.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeFsDiskAvailable.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeFsIoOperationsDataPoint adds a data point to elasticsearch.node.fs.io.operations metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeFsIoOperationsDataPoint(ts pdata.Timestamp, val int64, fs_directionAttributeValue string) {
	if !mb.config.ElasticsearchNodeFsIoOperations.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeFsIoOperations.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.FsDirection, pdata.NewAttributeValueString(fs_directionAttributeValue))
}

// RecordElasticsearchNodeHTTPConnectionsDataPoint adds a data point to elasticsearch.node.http.connections metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeHTTPConnectionsDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeHTTPConnections.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeHTTPConnections.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeJvmGcCollectionsCountDataPoint adds a data point to elasticsearch.node.jvm.gc.collections.count metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeJvmGcCollectionsCountDataPoint(ts pdata.Timestamp, val int64, generationAttributeValue string) {
	if !mb.config.ElasticsearchNodeJvmGcCollectionsCount.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeJvmGcCollectionsCount.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Generation, pdata.NewAttributeValueString(generationAttributeValue))
}

// RecordElasticsearchNodeJvmGcCollectionsElapsedDataPoint adds a data point to elasticsearch.node.jvm.gc.collections.elapsed metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeJvmGcCollectionsElapsedDataPoint(ts pdata.Timestamp, val int64, generationAttributeValue string) {
	if !mb.config.ElasticsearchNodeJvmGcCollectionsElapsed.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeJvmGcCollectionsElapsed.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Generation, pdata.NewAttributeValueString(generationAttributeValue))
}

// RecordElasticsearchNodeJvmMemoryHeapMaxDataPoint adds a data point to elasticsearch.node.jvm.memory.heap.max metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeJvmMemoryHeapMaxDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeJvmMemoryHeapMax.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeJvmMemoryHeapMax.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeJvmMemoryHeapUsedDataPoint adds a data point to elasticsearch.node.jvm.memory.heap.used metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeJvmMemoryHeapUsedDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeJvmMemoryHeapUsed.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeJvmMemoryHeapUsed.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeJvmMemoryNonheapUsedDataPoint adds a data point to elasticsearch.node.jvm.memory.nonheap.used metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeJvmMemoryNonheapUsedDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeJvmMemoryNonheapUsed.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeJvmMemoryNonheapUsed.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeJvmThreadsCountDataPoint adds a data point to elasticsearch.node.jvm.threads.count metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeJvmThreadsCountDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeJvmThreadsCount.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeJvmThreadsCount.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeJvmThreadsPeakDataPoint adds a data point to elasticsearch.node.jvm.threads.peak metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeJvmThreadsPeakDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeJvmThreadsPeak.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeJvmThreadsPeak.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeOpenFilesDataPoint adds a data point to elasticsearch.node.open_files metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeOpenFilesDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeOpenFiles.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeOpenFiles.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeOperationsCompletedDataPoint adds a data point to elasticsearch.node.operations.completed metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeOperationsCompletedDataPoint(ts pdata.Timestamp, val int64, operationAttributeValue string) {
	if !mb.config.ElasticsearchNodeOperationsCompleted.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeOperationsCompleted.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Operation, pdata.NewAttributeValueString(operationAttributeValue))
}

// RecordElasticsearchNodeOperationsTimeDataPoint adds a data point to elasticsearch.node.operations.time metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeOperationsTimeDataPoint(ts pdata.Timestamp, val int64, operationAttributeValue string) {
	if !mb.config.ElasticsearchNodeOperationsTime.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeOperationsTime.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Operation, pdata.NewAttributeValueString(operationAttributeValue))
}

// RecordElasticsearchNodeShardsSizeDataPoint adds a data point to elasticsearch.node.shards.size metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeShardsSizeDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeShardsSize.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeShardsSize.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeThreadPoolTasksFinishedDataPoint adds a data point to elasticsearch.node.thread_pool.tasks.finished metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeThreadPoolTasksFinishedDataPoint(ts pdata.Timestamp, val int64, thread_pool_nameAttributeValue string, task_stateAttributeValue string) {
	if !mb.config.ElasticsearchNodeThreadPoolTasksFinished.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeThreadPoolTasksFinished.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.ThreadPoolName, pdata.NewAttributeValueString(thread_pool_nameAttributeValue))
	dp.Attributes().Insert(A.TaskState, pdata.NewAttributeValueString(task_stateAttributeValue))
}

// RecordElasticsearchNodeThreadPoolTasksQueuedDataPoint adds a data point to elasticsearch.node.thread_pool.tasks.queued metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeThreadPoolTasksQueuedDataPoint(ts pdata.Timestamp, val int64, thread_pool_nameAttributeValue string) {
	if !mb.config.ElasticsearchNodeThreadPoolTasksQueued.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeThreadPoolTasksQueued.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.ThreadPoolName, pdata.NewAttributeValueString(thread_pool_nameAttributeValue))
}

// RecordElasticsearchNodeThreadPoolThreadsDataPoint adds a data point to elasticsearch.node.thread_pool.threads metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeThreadPoolThreadsDataPoint(ts pdata.Timestamp, val int64, thread_stateAttributeValue string) {
	if !mb.config.ElasticsearchNodeThreadPoolThreads.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeThreadPoolThreads.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.ThreadState, pdata.NewAttributeValueString(thread_stateAttributeValue))
}

// Attributes contains the possible metric attributes that can be used.
var Attributes = struct {
	// CacheName (The name of cache.)
	CacheName string
	// Direction (The direction of network data.)
	Direction string
	// DiskUsageState (The state of a section of space on disk.)
	DiskUsageState string
	// DocumentState (The state of the document.)
	DocumentState string
	// ElasticsearchClusterName (The name of the elasticsearch cluster.)
	ElasticsearchClusterName string
	// ElasticsearchNodeName (The name of the elasticsearch node.)
	ElasticsearchNodeName string
	// FsDirection (The direction of filesystem IO.)
	FsDirection string
	// Generation (The generation on which garbage collection was performed.)
	Generation string
	// Operation (The type of operation.)
	Operation string
	// ShardType (The state of the shard.)
	ShardType string
	// TaskState (The state of the task.)
	TaskState string
	// ThreadPoolName (The name of the thread pool.)
	ThreadPoolName string
	// ThreadState (The state of the thread.)
	ThreadState string
}{
	"cache_name",
	"direction",
	"state",
	"state",
	"elasticsearch.cluster.name",
	"elasticsearch.node.name",
	"direction",
	"generation",
	"operation",
	"type",
	"state",
	"thread_pool_name",
	"state",
}

// A is an alias for Attributes.
var A = Attributes

// AttributeCacheName are the possible values that the attribute "cache_name" can have.
var AttributeCacheName = struct {
	Fielddata string
	Query     string
}{
	"fielddata",
	"query",
}

// AttributeDirection are the possible values that the attribute "direction" can have.
var AttributeDirection = struct {
	Received string
	Sent     string
}{
	"received",
	"sent",
}

// AttributeDiskUsageState are the possible values that the attribute "disk_usage_state" can have.
var AttributeDiskUsageState = struct {
	Used string
	Free string
}{
	"used",
	"free",
}

// AttributeDocumentState are the possible values that the attribute "document_state" can have.
var AttributeDocumentState = struct {
	Active  string
	Deleted string
}{
	"active",
	"deleted",
}

// AttributeFsDirection are the possible values that the attribute "fs_direction" can have.
var AttributeFsDirection = struct {
	Read  string
	Write string
}{
	"read",
	"write",
}

// AttributeGeneration are the possible values that the attribute "generation" can have.
var AttributeGeneration = struct {
	Young string
	Old   string
}{
	"young",
	"old",
}

// AttributeOperation are the possible values that the attribute "operation" can have.
var AttributeOperation = struct {
	Index   string
	Delete  string
	Get     string
	Query   string
	Fetch   string
	Scroll  string
	Suggest string
	Merge   string
	Refresh string
	Flush   string
	Warmer  string
}{
	"index",
	"delete",
	"get",
	"query",
	"fetch",
	"scroll",
	"suggest",
	"merge",
	"refresh",
	"flush",
	"warmer",
}

// AttributeShardType are the possible values that the attribute "shard_type" can have.
var AttributeShardType = struct {
	Active       string
	Relocating   string
	Initializing string
	Unassigned   string
}{
	"active",
	"relocating",
	"initializing",
	"unassigned",
}

// AttributeTaskState are the possible values that the attribute "task_state" can have.
var AttributeTaskState = struct {
	Rejected  string
	Completed string
}{
	"rejected",
	"completed",
}

// AttributeThreadState are the possible values that the attribute "thread_state" can have.
var AttributeThreadState = struct {
	Active string
	Idle   string
}{
	"active",
	"idle",
}
