// Copyright The OpenTelemetry Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/model/pdata"
)

// MetricSettings provides common settings for a particular metric.
type MetricSettings struct {
	Enabled bool `mapstructure:"enabled"`
}

// MetricsSettings provides settings for elasticsearchreceiver metrics.
type MetricsSettings struct {
	ElasticsearchClusterDataNodes            MetricSettings `mapstructure:"elasticsearch.cluster.data_nodes"`
	ElasticsearchClusterHealth               MetricSettings `mapstructure:"elasticsearch.cluster.health"`
	ElasticsearchClusterNodes                MetricSettings `mapstructure:"elasticsearch.cluster.nodes"`
	ElasticsearchClusterShards               MetricSettings `mapstructure:"elasticsearch.cluster.shards"`
	ElasticsearchNodeCacheEvictions          MetricSettings `mapstructure:"elasticsearch.node.cache.evictions"`
	ElasticsearchNodeCacheMemoryUsage        MetricSettings `mapstructure:"elasticsearch.node.cache.memory.usage"`
	ElasticsearchNodeDocuments               MetricSettings `mapstructure:"elasticsearch.node.documents"`
	ElasticsearchNodeFsDiskFree              MetricSettings `mapstructure:"elasticsearch.node.fs.disk.free"`
	ElasticsearchNodeFsDiskUsage             MetricSettings `mapstructure:"elasticsearch.node.fs.disk.usage"`
	ElasticsearchNodeFsIoOperations          MetricSettings `mapstructure:"elasticsearch.node.fs.io.operations"`
	ElasticsearchNodeHTTPConnections         MetricSettings `mapstructure:"elasticsearch.node.http.connections"`
	ElasticsearchNodeJvmGcCollectionsCount   MetricSettings `mapstructure:"elasticsearch.node.jvm.gc.collections.count"`
	ElasticsearchNodeJvmGcCollectionsTime    MetricSettings `mapstructure:"elasticsearch.node.jvm.gc.collections.time"`
	ElasticsearchNodeJvmMemoryUsage          MetricSettings `mapstructure:"elasticsearch.node.jvm.memory.usage"`
	ElasticsearchNodeJvmThreadsCount         MetricSettings `mapstructure:"elasticsearch.node.jvm.threads.count"`
	ElasticsearchNodeJvmThreadsPeak          MetricSettings `mapstructure:"elasticsearch.node.jvm.threads.peak"`
	ElasticsearchNodeNetworkConnections      MetricSettings `mapstructure:"elasticsearch.node.network.connections"`
	ElasticsearchNodeNetworkIo               MetricSettings `mapstructure:"elasticsearch.node.network.io"`
	ElasticsearchNodeOpenFiles               MetricSettings `mapstructure:"elasticsearch.node.open_files"`
	ElasticsearchNodeOperationsCompleted     MetricSettings `mapstructure:"elasticsearch.node.operations.completed"`
	ElasticsearchNodeOperationsTime          MetricSettings `mapstructure:"elasticsearch.node.operations.time"`
	ElasticsearchNodeShardsSize              MetricSettings `mapstructure:"elasticsearch.node.shards.size"`
	ElasticsearchNodeThreadPoolFinishedTasks MetricSettings `mapstructure:"elasticsearch.node.thread_pool.finished_tasks"`
	ElasticsearchNodeThreadPoolQueuedTasks   MetricSettings `mapstructure:"elasticsearch.node.thread_pool.queued_tasks"`
	ElasticsearchNodeThreadPoolThreads       MetricSettings `mapstructure:"elasticsearch.node.thread_pool.threads"`
}

func DefaultMetricsSettings() MetricsSettings {
	return MetricsSettings{
		ElasticsearchClusterDataNodes: MetricSettings{
			Enabled: false,
		},
		ElasticsearchClusterHealth: MetricSettings{
			Enabled: false,
		},
		ElasticsearchClusterNodes: MetricSettings{
			Enabled: false,
		},
		ElasticsearchClusterShards: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeCacheEvictions: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeCacheMemoryUsage: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeDocuments: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeFsDiskFree: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeFsDiskUsage: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeFsIoOperations: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeHTTPConnections: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeJvmGcCollectionsCount: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeJvmGcCollectionsTime: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeJvmMemoryUsage: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeJvmThreadsCount: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeJvmThreadsPeak: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeNetworkConnections: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeNetworkIo: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeOpenFiles: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeOperationsCompleted: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeOperationsTime: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeShardsSize: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeThreadPoolFinishedTasks: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeThreadPoolQueuedTasks: MetricSettings{
			Enabled: false,
		},
		ElasticsearchNodeThreadPoolThreads: MetricSettings{
			Enabled: false,
		},
	}
}

// metric holds data for generated metric and keeps track of data points slice capacity.
type metric struct {
	data     pdata.Metric // data buffer for generated metric.
	capacity int          // max observed number of data points added to the metric.
}

func (m *metric) updateCapacity(dpLen int) {
	if dpLen > m.capacity {
		m.capacity = dpLen
	}
}

func newMetric() metric {
	return metric{data: pdata.NewMetric()}
}

type metrics struct {
	elasticsearchClusterDataNodes            metric
	elasticsearchClusterHealth               metric
	elasticsearchClusterNodes                metric
	elasticsearchClusterShards               metric
	elasticsearchNodeCacheEvictions          metric
	elasticsearchNodeCacheMemoryUsage        metric
	elasticsearchNodeDocuments               metric
	elasticsearchNodeFsDiskFree              metric
	elasticsearchNodeFsDiskUsage             metric
	elasticsearchNodeFsIoOperations          metric
	elasticsearchNodeHTTPConnections         metric
	elasticsearchNodeJvmGcCollectionsCount   metric
	elasticsearchNodeJvmGcCollectionsTime    metric
	elasticsearchNodeJvmMemoryUsage          metric
	elasticsearchNodeJvmThreadsCount         metric
	elasticsearchNodeJvmThreadsPeak          metric
	elasticsearchNodeNetworkConnections      metric
	elasticsearchNodeNetworkIo               metric
	elasticsearchNodeOpenFiles               metric
	elasticsearchNodeOperationsCompleted     metric
	elasticsearchNodeOperationsTime          metric
	elasticsearchNodeShardsSize              metric
	elasticsearchNodeThreadPoolFinishedTasks metric
	elasticsearchNodeThreadPoolQueuedTasks   metric
	elasticsearchNodeThreadPoolThreads       metric
}

func newMetrics(config MetricsSettings) metrics {
	ms := metrics{}
	if config.ElasticsearchClusterDataNodes.Enabled {
		ms.elasticsearchClusterDataNodes = newMetric()
	}
	if config.ElasticsearchClusterHealth.Enabled {
		ms.elasticsearchClusterHealth = newMetric()
	}
	if config.ElasticsearchClusterNodes.Enabled {
		ms.elasticsearchClusterNodes = newMetric()
	}
	if config.ElasticsearchClusterShards.Enabled {
		ms.elasticsearchClusterShards = newMetric()
	}
	if config.ElasticsearchNodeCacheEvictions.Enabled {
		ms.elasticsearchNodeCacheEvictions = newMetric()
	}
	if config.ElasticsearchNodeCacheMemoryUsage.Enabled {
		ms.elasticsearchNodeCacheMemoryUsage = newMetric()
	}
	if config.ElasticsearchNodeDocuments.Enabled {
		ms.elasticsearchNodeDocuments = newMetric()
	}
	if config.ElasticsearchNodeFsDiskFree.Enabled {
		ms.elasticsearchNodeFsDiskFree = newMetric()
	}
	if config.ElasticsearchNodeFsDiskUsage.Enabled {
		ms.elasticsearchNodeFsDiskUsage = newMetric()
	}
	if config.ElasticsearchNodeFsIoOperations.Enabled {
		ms.elasticsearchNodeFsIoOperations = newMetric()
	}
	if config.ElasticsearchNodeHTTPConnections.Enabled {
		ms.elasticsearchNodeHTTPConnections = newMetric()
	}
	if config.ElasticsearchNodeJvmGcCollectionsCount.Enabled {
		ms.elasticsearchNodeJvmGcCollectionsCount = newMetric()
	}
	if config.ElasticsearchNodeJvmGcCollectionsTime.Enabled {
		ms.elasticsearchNodeJvmGcCollectionsTime = newMetric()
	}
	if config.ElasticsearchNodeJvmMemoryUsage.Enabled {
		ms.elasticsearchNodeJvmMemoryUsage = newMetric()
	}
	if config.ElasticsearchNodeJvmThreadsCount.Enabled {
		ms.elasticsearchNodeJvmThreadsCount = newMetric()
	}
	if config.ElasticsearchNodeJvmThreadsPeak.Enabled {
		ms.elasticsearchNodeJvmThreadsPeak = newMetric()
	}
	if config.ElasticsearchNodeNetworkConnections.Enabled {
		ms.elasticsearchNodeNetworkConnections = newMetric()
	}
	if config.ElasticsearchNodeNetworkIo.Enabled {
		ms.elasticsearchNodeNetworkIo = newMetric()
	}
	if config.ElasticsearchNodeOpenFiles.Enabled {
		ms.elasticsearchNodeOpenFiles = newMetric()
	}
	if config.ElasticsearchNodeOperationsCompleted.Enabled {
		ms.elasticsearchNodeOperationsCompleted = newMetric()
	}
	if config.ElasticsearchNodeOperationsTime.Enabled {
		ms.elasticsearchNodeOperationsTime = newMetric()
	}
	if config.ElasticsearchNodeShardsSize.Enabled {
		ms.elasticsearchNodeShardsSize = newMetric()
	}
	if config.ElasticsearchNodeThreadPoolFinishedTasks.Enabled {
		ms.elasticsearchNodeThreadPoolFinishedTasks = newMetric()
	}
	if config.ElasticsearchNodeThreadPoolQueuedTasks.Enabled {
		ms.elasticsearchNodeThreadPoolQueuedTasks = newMetric()
	}
	if config.ElasticsearchNodeThreadPoolThreads.Enabled {
		ms.elasticsearchNodeThreadPoolThreads = newMetric()
	}
	return ms
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user configuration.
type MetricsBuilder struct {
	config    MetricsSettings
	startTime pdata.Timestamp
	metrics   metrics
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pdata.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(config MetricsSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:    config,
		startTime: pdata.NewTimestampFromTime(time.Now()),
		metrics:   newMetrics(config),
	}

	for _, op := range options {
		op(mb)
	}

	mb.initMetrics()
	return mb
}

// Emit appends generated metrics to a pdata.MetricsSlice and updates the internal state to be ready for recording
// another set of data points. This function will be doing all transformations required to produce metric representation
// defined in metadata and user configuration, e.g. delta/cumulative translation.
func (mb *MetricsBuilder) Emit(metrics pdata.MetricSlice) {
	if mb.config.ElasticsearchClusterDataNodes.Enabled && mb.metrics.elasticsearchClusterDataNodes.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchClusterDataNodes.updateCapacity(mb.metrics.elasticsearchClusterDataNodes.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchClusterDataNodes.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchClusterHealth.Enabled && mb.metrics.elasticsearchClusterHealth.data.Gauge().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchClusterHealth.updateCapacity(mb.metrics.elasticsearchClusterHealth.data.Gauge().DataPoints().Len())
		mb.metrics.elasticsearchClusterHealth.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchClusterNodes.Enabled && mb.metrics.elasticsearchClusterNodes.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchClusterNodes.updateCapacity(mb.metrics.elasticsearchClusterNodes.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchClusterNodes.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchClusterShards.Enabled && mb.metrics.elasticsearchClusterShards.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchClusterShards.updateCapacity(mb.metrics.elasticsearchClusterShards.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchClusterShards.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeCacheEvictions.Enabled && mb.metrics.elasticsearchNodeCacheEvictions.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeCacheEvictions.updateCapacity(mb.metrics.elasticsearchNodeCacheEvictions.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeCacheEvictions.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeCacheMemoryUsage.Enabled && mb.metrics.elasticsearchNodeCacheMemoryUsage.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeCacheMemoryUsage.updateCapacity(mb.metrics.elasticsearchNodeCacheMemoryUsage.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeCacheMemoryUsage.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeDocuments.Enabled && mb.metrics.elasticsearchNodeDocuments.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeDocuments.updateCapacity(mb.metrics.elasticsearchNodeDocuments.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeDocuments.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeFsDiskFree.Enabled && mb.metrics.elasticsearchNodeFsDiskFree.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeFsDiskFree.updateCapacity(mb.metrics.elasticsearchNodeFsDiskFree.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeFsDiskFree.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeFsDiskUsage.Enabled && mb.metrics.elasticsearchNodeFsDiskUsage.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeFsDiskUsage.updateCapacity(mb.metrics.elasticsearchNodeFsDiskUsage.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeFsDiskUsage.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeFsIoOperations.Enabled && mb.metrics.elasticsearchNodeFsIoOperations.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeFsIoOperations.updateCapacity(mb.metrics.elasticsearchNodeFsIoOperations.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeFsIoOperations.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeHTTPConnections.Enabled && mb.metrics.elasticsearchNodeHTTPConnections.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeHTTPConnections.updateCapacity(mb.metrics.elasticsearchNodeHTTPConnections.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeHTTPConnections.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeJvmGcCollectionsCount.Enabled && mb.metrics.elasticsearchNodeJvmGcCollectionsCount.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeJvmGcCollectionsCount.updateCapacity(mb.metrics.elasticsearchNodeJvmGcCollectionsCount.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeJvmGcCollectionsCount.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeJvmGcCollectionsTime.Enabled && mb.metrics.elasticsearchNodeJvmGcCollectionsTime.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeJvmGcCollectionsTime.updateCapacity(mb.metrics.elasticsearchNodeJvmGcCollectionsTime.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeJvmGcCollectionsTime.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeJvmMemoryUsage.Enabled && mb.metrics.elasticsearchNodeJvmMemoryUsage.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeJvmMemoryUsage.updateCapacity(mb.metrics.elasticsearchNodeJvmMemoryUsage.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeJvmMemoryUsage.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeJvmThreadsCount.Enabled && mb.metrics.elasticsearchNodeJvmThreadsCount.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeJvmThreadsCount.updateCapacity(mb.metrics.elasticsearchNodeJvmThreadsCount.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeJvmThreadsCount.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeJvmThreadsPeak.Enabled && mb.metrics.elasticsearchNodeJvmThreadsPeak.data.Gauge().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeJvmThreadsPeak.updateCapacity(mb.metrics.elasticsearchNodeJvmThreadsPeak.data.Gauge().DataPoints().Len())
		mb.metrics.elasticsearchNodeJvmThreadsPeak.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeNetworkConnections.Enabled && mb.metrics.elasticsearchNodeNetworkConnections.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeNetworkConnections.updateCapacity(mb.metrics.elasticsearchNodeNetworkConnections.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeNetworkConnections.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeNetworkIo.Enabled && mb.metrics.elasticsearchNodeNetworkIo.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeNetworkIo.updateCapacity(mb.metrics.elasticsearchNodeNetworkIo.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeNetworkIo.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeOpenFiles.Enabled && mb.metrics.elasticsearchNodeOpenFiles.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeOpenFiles.updateCapacity(mb.metrics.elasticsearchNodeOpenFiles.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeOpenFiles.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeOperationsCompleted.Enabled && mb.metrics.elasticsearchNodeOperationsCompleted.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeOperationsCompleted.updateCapacity(mb.metrics.elasticsearchNodeOperationsCompleted.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeOperationsCompleted.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeOperationsTime.Enabled && mb.metrics.elasticsearchNodeOperationsTime.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeOperationsTime.updateCapacity(mb.metrics.elasticsearchNodeOperationsTime.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeOperationsTime.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeShardsSize.Enabled && mb.metrics.elasticsearchNodeShardsSize.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeShardsSize.updateCapacity(mb.metrics.elasticsearchNodeShardsSize.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeShardsSize.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeThreadPoolFinishedTasks.Enabled && mb.metrics.elasticsearchNodeThreadPoolFinishedTasks.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeThreadPoolFinishedTasks.updateCapacity(mb.metrics.elasticsearchNodeThreadPoolFinishedTasks.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeThreadPoolFinishedTasks.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeThreadPoolQueuedTasks.Enabled && mb.metrics.elasticsearchNodeThreadPoolQueuedTasks.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeThreadPoolQueuedTasks.updateCapacity(mb.metrics.elasticsearchNodeThreadPoolQueuedTasks.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeThreadPoolQueuedTasks.data.MoveTo(metrics.AppendEmpty())
	}
	if mb.config.ElasticsearchNodeThreadPoolThreads.Enabled && mb.metrics.elasticsearchNodeThreadPoolThreads.data.Sum().DataPoints().Len() > 0 {
		mb.metrics.elasticsearchNodeThreadPoolThreads.updateCapacity(mb.metrics.elasticsearchNodeThreadPoolThreads.data.Sum().DataPoints().Len())
		mb.metrics.elasticsearchNodeThreadPoolThreads.data.MoveTo(metrics.AppendEmpty())
	}

	// Reset metric data points collection.
	mb.initMetrics()
}

// initElasticsearchClusterDataNodesMetric builds new elasticsearch.cluster.data_nodes metric.
func (mb *MetricsBuilder) initElasticsearchClusterDataNodesMetric() {
	metric := mb.metrics.elasticsearchClusterDataNodes
	metric.data.SetName("elasticsearch.cluster.data_nodes")
	metric.data.SetDescription("Number of data nodes in the cluster.")
	metric.data.SetUnit("{nodes}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchClusterHealthMetric builds new elasticsearch.cluster.health metric.
func (mb *MetricsBuilder) initElasticsearchClusterHealthMetric() {
	metric := mb.metrics.elasticsearchClusterHealth
	metric.data.SetName("elasticsearch.cluster.health")
	metric.data.SetDescription("The health of the cluster.")
	metric.data.SetUnit("{stats}")
	metric.data.SetDataType(pdata.MetricDataTypeGauge)
}

// initElasticsearchClusterNodesMetric builds new elasticsearch.cluster.nodes metric.
func (mb *MetricsBuilder) initElasticsearchClusterNodesMetric() {
	metric := mb.metrics.elasticsearchClusterNodes
	metric.data.SetName("elasticsearch.cluster.nodes")
	metric.data.SetDescription("Total number of nodes in the cluster.")
	metric.data.SetUnit("{nodes}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchClusterShardsMetric builds new elasticsearch.cluster.shards metric.
func (mb *MetricsBuilder) initElasticsearchClusterShardsMetric() {
	metric := mb.metrics.elasticsearchClusterShards
	metric.data.SetName("elasticsearch.cluster.shards")
	metric.data.SetDescription("Number of shards in the cluster.")
	metric.data.SetUnit("{shards}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeCacheEvictionsMetric builds new elasticsearch.node.cache.evictions metric.
func (mb *MetricsBuilder) initElasticsearchNodeCacheEvictionsMetric() {
	metric := mb.metrics.elasticsearchNodeCacheEvictions
	metric.data.SetName("elasticsearch.node.cache.evictions")
	metric.data.SetDescription("The number of evictions from the cache.")
	metric.data.SetUnit("{evictions}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(true)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeCacheMemoryUsageMetric builds new elasticsearch.node.cache.memory.usage metric.
func (mb *MetricsBuilder) initElasticsearchNodeCacheMemoryUsageMetric() {
	metric := mb.metrics.elasticsearchNodeCacheMemoryUsage
	metric.data.SetName("elasticsearch.node.cache.memory.usage")
	metric.data.SetDescription("Size in bytes of the cache.")
	metric.data.SetUnit("By")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeDocumentsMetric builds new elasticsearch.node.documents metric.
func (mb *MetricsBuilder) initElasticsearchNodeDocumentsMetric() {
	metric := mb.metrics.elasticsearchNodeDocuments
	metric.data.SetName("elasticsearch.node.documents")
	metric.data.SetDescription("Number of documents on the node.")
	metric.data.SetUnit("{documents}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeFsDiskFreeMetric builds new elasticsearch.node.fs.disk.free metric.
func (mb *MetricsBuilder) initElasticsearchNodeFsDiskFreeMetric() {
	metric := mb.metrics.elasticsearchNodeFsDiskFree
	metric.data.SetName("elasticsearch.node.fs.disk.free")
	metric.data.SetDescription("The amount of free disk space  that may be used by elasticsearch across all file stores for this node.")
	metric.data.SetUnit("By")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchNodeFsDiskUsageMetric builds new elasticsearch.node.fs.disk.usage metric.
func (mb *MetricsBuilder) initElasticsearchNodeFsDiskUsageMetric() {
	metric := mb.metrics.elasticsearchNodeFsDiskUsage
	metric.data.SetName("elasticsearch.node.fs.disk.usage")
	metric.data.SetDescription("The amount of used disk space across all file stores for this node.")
	metric.data.SetUnit("By")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchNodeFsIoOperationsMetric builds new elasticsearch.node.fs.io.operations metric.
func (mb *MetricsBuilder) initElasticsearchNodeFsIoOperationsMetric() {
	metric := mb.metrics.elasticsearchNodeFsIoOperations
	metric.data.SetName("elasticsearch.node.fs.io.operations")
	metric.data.SetDescription("The number of io operations completed by elasticsearch across all file stores. Only available on Linux nodes.")
	metric.data.SetUnit("{operations}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(true)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeHTTPConnectionsMetric builds new elasticsearch.node.http.connections metric.
func (mb *MetricsBuilder) initElasticsearchNodeHTTPConnectionsMetric() {
	metric := mb.metrics.elasticsearchNodeHTTPConnections
	metric.data.SetName("elasticsearch.node.http.connections")
	metric.data.SetDescription("Number of HTTP connections to the node.")
	metric.data.SetUnit("{connections}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchNodeJvmGcCollectionsCountMetric builds new elasticsearch.node.jvm.gc.collections.count metric.
func (mb *MetricsBuilder) initElasticsearchNodeJvmGcCollectionsCountMetric() {
	metric := mb.metrics.elasticsearchNodeJvmGcCollectionsCount
	metric.data.SetName("elasticsearch.node.jvm.gc.collections.count")
	metric.data.SetDescription("The number of GC collections performed by the JVM.")
	metric.data.SetUnit("{collections}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(true)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeJvmGcCollectionsTimeMetric builds new elasticsearch.node.jvm.gc.collections.time metric.
func (mb *MetricsBuilder) initElasticsearchNodeJvmGcCollectionsTimeMetric() {
	metric := mb.metrics.elasticsearchNodeJvmGcCollectionsTime
	metric.data.SetName("elasticsearch.node.jvm.gc.collections.time")
	metric.data.SetDescription("Total time spent by the JVM running the GC.")
	metric.data.SetUnit("ms")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(true)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeJvmMemoryUsageMetric builds new elasticsearch.node.jvm.memory.usage metric.
func (mb *MetricsBuilder) initElasticsearchNodeJvmMemoryUsageMetric() {
	metric := mb.metrics.elasticsearchNodeJvmMemoryUsage
	metric.data.SetName("elasticsearch.node.jvm.memory.usage")
	metric.data.SetDescription("Memory used by the JVM.")
	metric.data.SetUnit("By")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeJvmThreadsCountMetric builds new elasticsearch.node.jvm.threads.count metric.
func (mb *MetricsBuilder) initElasticsearchNodeJvmThreadsCountMetric() {
	metric := mb.metrics.elasticsearchNodeJvmThreadsCount
	metric.data.SetName("elasticsearch.node.jvm.threads.count")
	metric.data.SetDescription("Number of open threads in the node's JVM process.")
	metric.data.SetUnit("{threads}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchNodeJvmThreadsPeakMetric builds new elasticsearch.node.jvm.threads.peak metric.
func (mb *MetricsBuilder) initElasticsearchNodeJvmThreadsPeakMetric() {
	metric := mb.metrics.elasticsearchNodeJvmThreadsPeak
	metric.data.SetName("elasticsearch.node.jvm.threads.peak")
	metric.data.SetDescription("Maximum number of concurrently running threads in the node's JVM process.")
	metric.data.SetUnit("{threads}")
	metric.data.SetDataType(pdata.MetricDataTypeGauge)
}

// initElasticsearchNodeNetworkConnectionsMetric builds new elasticsearch.node.network.connections metric.
func (mb *MetricsBuilder) initElasticsearchNodeNetworkConnectionsMetric() {
	metric := mb.metrics.elasticsearchNodeNetworkConnections
	metric.data.SetName("elasticsearch.node.network.connections")
	metric.data.SetDescription("Number of open internal tcp connections for internal cluster communication")
	metric.data.SetUnit("{connections}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchNodeNetworkIoMetric builds new elasticsearch.node.network.io metric.
func (mb *MetricsBuilder) initElasticsearchNodeNetworkIoMetric() {
	metric := mb.metrics.elasticsearchNodeNetworkIo
	metric.data.SetName("elasticsearch.node.network.io")
	metric.data.SetDescription("Number of bytes sent and received on the network for internal cluster communication.")
	metric.data.SetUnit("By")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(true)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeOpenFilesMetric builds new elasticsearch.node.open_files metric.
func (mb *MetricsBuilder) initElasticsearchNodeOpenFilesMetric() {
	metric := mb.metrics.elasticsearchNodeOpenFiles
	metric.data.SetName("elasticsearch.node.open_files")
	metric.data.SetDescription("Number of open file descriptors held by the node.")
	metric.data.SetUnit("{files}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchNodeOperationsCompletedMetric builds new elasticsearch.node.operations.completed metric.
func (mb *MetricsBuilder) initElasticsearchNodeOperationsCompletedMetric() {
	metric := mb.metrics.elasticsearchNodeOperationsCompleted
	metric.data.SetName("elasticsearch.node.operations.completed")
	metric.data.SetDescription("Number of operations completed.")
	metric.data.SetUnit("{operations}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(true)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeOperationsTimeMetric builds new elasticsearch.node.operations.time metric.
func (mb *MetricsBuilder) initElasticsearchNodeOperationsTimeMetric() {
	metric := mb.metrics.elasticsearchNodeOperationsTime
	metric.data.SetName("elasticsearch.node.operations.time")
	metric.data.SetDescription("Time spent on operations.")
	metric.data.SetUnit("ms")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(true)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeShardsSizeMetric builds new elasticsearch.node.shards.size metric.
func (mb *MetricsBuilder) initElasticsearchNodeShardsSizeMetric() {
	metric := mb.metrics.elasticsearchNodeShardsSize
	metric.data.SetName("elasticsearch.node.shards.size")
	metric.data.SetDescription("Size in bytes of the shards assigned to this node.")
	metric.data.SetUnit("By")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

// initElasticsearchNodeThreadPoolFinishedTasksMetric builds new elasticsearch.node.thread_pool.finished_tasks metric.
func (mb *MetricsBuilder) initElasticsearchNodeThreadPoolFinishedTasksMetric() {
	metric := mb.metrics.elasticsearchNodeThreadPoolFinishedTasks
	metric.data.SetName("elasticsearch.node.thread_pool.finished_tasks")
	metric.data.SetDescription("Number of tasks finished by the thread pool")
	metric.data.SetUnit("{tasks}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(true)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeThreadPoolQueuedTasksMetric builds new elasticsearch.node.thread_pool.queued_tasks metric.
func (mb *MetricsBuilder) initElasticsearchNodeThreadPoolQueuedTasksMetric() {
	metric := mb.metrics.elasticsearchNodeThreadPoolQueuedTasks
	metric.data.SetName("elasticsearch.node.thread_pool.queued_tasks")
	metric.data.SetDescription("Number of queued tasks in the thread pool.")
	metric.data.SetUnit("{tasks}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initElasticsearchNodeThreadPoolThreadsMetric builds new elasticsearch.node.thread_pool.threads metric.
func (mb *MetricsBuilder) initElasticsearchNodeThreadPoolThreadsMetric() {
	metric := mb.metrics.elasticsearchNodeThreadPoolThreads
	metric.data.SetName("elasticsearch.node.thread_pool.threads")
	metric.data.SetDescription("Number of the threads in the thread pool.")
	metric.data.SetUnit("{threads}")
	metric.data.SetDataType(pdata.MetricDataTypeSum)
	metric.data.Sum().SetIsMonotonic(false)
	metric.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	metric.data.Sum().DataPoints().EnsureCapacity(metric.capacity)
}

// initMetrics initializes metrics.
func (mb *MetricsBuilder) initMetrics() {
	if mb.config.ElasticsearchClusterDataNodes.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchClusterDataNodesMetric()
	}
	if mb.config.ElasticsearchClusterHealth.Enabled {
		// TODO: Use metric.data.Gauge().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchClusterHealthMetric()
	}
	if mb.config.ElasticsearchClusterNodes.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchClusterNodesMetric()
	}
	if mb.config.ElasticsearchClusterShards.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchClusterShardsMetric()
	}
	if mb.config.ElasticsearchNodeCacheEvictions.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeCacheEvictionsMetric()
	}
	if mb.config.ElasticsearchNodeCacheMemoryUsage.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeCacheMemoryUsageMetric()
	}
	if mb.config.ElasticsearchNodeDocuments.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeDocumentsMetric()
	}
	if mb.config.ElasticsearchNodeFsDiskFree.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeFsDiskFreeMetric()
	}
	if mb.config.ElasticsearchNodeFsDiskUsage.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeFsDiskUsageMetric()
	}
	if mb.config.ElasticsearchNodeFsIoOperations.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeFsIoOperationsMetric()
	}
	if mb.config.ElasticsearchNodeHTTPConnections.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeHTTPConnectionsMetric()
	}
	if mb.config.ElasticsearchNodeJvmGcCollectionsCount.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeJvmGcCollectionsCountMetric()
	}
	if mb.config.ElasticsearchNodeJvmGcCollectionsTime.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeJvmGcCollectionsTimeMetric()
	}
	if mb.config.ElasticsearchNodeJvmMemoryUsage.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeJvmMemoryUsageMetric()
	}
	if mb.config.ElasticsearchNodeJvmThreadsCount.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeJvmThreadsCountMetric()
	}
	if mb.config.ElasticsearchNodeJvmThreadsPeak.Enabled {
		// TODO: Use metric.data.Gauge().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeJvmThreadsPeakMetric()
	}
	if mb.config.ElasticsearchNodeNetworkConnections.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeNetworkConnectionsMetric()
	}
	if mb.config.ElasticsearchNodeNetworkIo.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeNetworkIoMetric()
	}
	if mb.config.ElasticsearchNodeOpenFiles.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeOpenFilesMetric()
	}
	if mb.config.ElasticsearchNodeOperationsCompleted.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeOperationsCompletedMetric()
	}
	if mb.config.ElasticsearchNodeOperationsTime.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeOperationsTimeMetric()
	}
	if mb.config.ElasticsearchNodeShardsSize.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeShardsSizeMetric()
	}
	if mb.config.ElasticsearchNodeThreadPoolFinishedTasks.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeThreadPoolFinishedTasksMetric()
	}
	if mb.config.ElasticsearchNodeThreadPoolQueuedTasks.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeThreadPoolQueuedTasksMetric()
	}
	if mb.config.ElasticsearchNodeThreadPoolThreads.Enabled {
		// TODO: Use metric.data.Sum().DataPoints().Clear() instead of rebuilding
		// the metrics once the Clear method is available.
		mb.initElasticsearchNodeThreadPoolThreadsMetric()
	}
}

// RecordElasticsearchClusterDataNodesDataPoint adds a data point to elasticsearch.cluster.data_nodes metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchClusterDataNodesDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchClusterDataNodes.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchClusterDataNodes.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchClusterHealthDataPoint adds a data point to elasticsearch.cluster.health metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchClusterHealthDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchClusterHealth.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchClusterHealth.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchClusterNodesDataPoint adds a data point to elasticsearch.cluster.nodes metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchClusterNodesDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchClusterNodes.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchClusterNodes.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchClusterShardsDataPoint adds a data point to elasticsearch.cluster.shards metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchClusterShardsDataPoint(ts pdata.Timestamp, val int64, shard_typeAttributeValue string) {
	if !mb.config.ElasticsearchClusterShards.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchClusterShards.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.ShardType, pdata.NewAttributeValueString(shard_typeAttributeValue))
}

// RecordElasticsearchNodeCacheEvictionsDataPoint adds a data point to elasticsearch.node.cache.evictions metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeCacheEvictionsDataPoint(ts pdata.Timestamp, val int64, cache_nameAttributeValue string) {
	if !mb.config.ElasticsearchNodeCacheEvictions.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeCacheEvictions.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.CacheName, pdata.NewAttributeValueString(cache_nameAttributeValue))
}

// RecordElasticsearchNodeCacheMemoryUsageDataPoint adds a data point to elasticsearch.node.cache.memory.usage metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeCacheMemoryUsageDataPoint(ts pdata.Timestamp, val int64, cache_nameAttributeValue string) {
	if !mb.config.ElasticsearchNodeCacheMemoryUsage.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeCacheMemoryUsage.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.CacheName, pdata.NewAttributeValueString(cache_nameAttributeValue))
}

// RecordElasticsearchNodeDocumentsDataPoint adds a data point to elasticsearch.node.documents metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeDocumentsDataPoint(ts pdata.Timestamp, val int64, document_typeAttributeValue string) {
	if !mb.config.ElasticsearchNodeDocuments.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeDocuments.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.DocumentType, pdata.NewAttributeValueString(document_typeAttributeValue))
}

// RecordElasticsearchNodeFsDiskFreeDataPoint adds a data point to elasticsearch.node.fs.disk.free metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeFsDiskFreeDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeFsDiskFree.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeFsDiskFree.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeFsDiskUsageDataPoint adds a data point to elasticsearch.node.fs.disk.usage metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeFsDiskUsageDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeFsDiskUsage.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeFsDiskUsage.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeFsIoOperationsDataPoint adds a data point to elasticsearch.node.fs.io.operations metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeFsIoOperationsDataPoint(ts pdata.Timestamp, val int64, fs_operation_typeAttributeValue string) {
	if !mb.config.ElasticsearchNodeFsIoOperations.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeFsIoOperations.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.FsOperationType, pdata.NewAttributeValueString(fs_operation_typeAttributeValue))
}

// RecordElasticsearchNodeHTTPConnectionsDataPoint adds a data point to elasticsearch.node.http.connections metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeHTTPConnectionsDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeHTTPConnections.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeHTTPConnections.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeJvmGcCollectionsCountDataPoint adds a data point to elasticsearch.node.jvm.gc.collections.count metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeJvmGcCollectionsCountDataPoint(ts pdata.Timestamp, val int64, gc_typeAttributeValue string) {
	if !mb.config.ElasticsearchNodeJvmGcCollectionsCount.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeJvmGcCollectionsCount.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.GcType, pdata.NewAttributeValueString(gc_typeAttributeValue))
}

// RecordElasticsearchNodeJvmGcCollectionsTimeDataPoint adds a data point to elasticsearch.node.jvm.gc.collections.time metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeJvmGcCollectionsTimeDataPoint(ts pdata.Timestamp, val int64, gc_typeAttributeValue string) {
	if !mb.config.ElasticsearchNodeJvmGcCollectionsTime.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeJvmGcCollectionsTime.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.GcType, pdata.NewAttributeValueString(gc_typeAttributeValue))
}

// RecordElasticsearchNodeJvmMemoryUsageDataPoint adds a data point to elasticsearch.node.jvm.memory.usage metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeJvmMemoryUsageDataPoint(ts pdata.Timestamp, val int64, memory_typeAttributeValue string) {
	if !mb.config.ElasticsearchNodeJvmMemoryUsage.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeJvmMemoryUsage.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.MemoryType, pdata.NewAttributeValueString(memory_typeAttributeValue))
}

// RecordElasticsearchNodeJvmThreadsCountDataPoint adds a data point to elasticsearch.node.jvm.threads.count metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeJvmThreadsCountDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeJvmThreadsCount.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeJvmThreadsCount.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeJvmThreadsPeakDataPoint adds a data point to elasticsearch.node.jvm.threads.peak metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeJvmThreadsPeakDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeJvmThreadsPeak.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeJvmThreadsPeak.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeNetworkConnectionsDataPoint adds a data point to elasticsearch.node.network.connections metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeNetworkConnectionsDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeNetworkConnections.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeNetworkConnections.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeNetworkIoDataPoint adds a data point to elasticsearch.node.network.io metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeNetworkIoDataPoint(ts pdata.Timestamp, val int64, directionAttributeValue string) {
	if !mb.config.ElasticsearchNodeNetworkIo.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeNetworkIo.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Direction, pdata.NewAttributeValueString(directionAttributeValue))
}

// RecordElasticsearchNodeOpenFilesDataPoint adds a data point to elasticsearch.node.open_files metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeOpenFilesDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeOpenFiles.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeOpenFiles.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeOperationsCompletedDataPoint adds a data point to elasticsearch.node.operations.completed metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeOperationsCompletedDataPoint(ts pdata.Timestamp, val int64, operation_typeAttributeValue string) {
	if !mb.config.ElasticsearchNodeOperationsCompleted.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeOperationsCompleted.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.OperationType, pdata.NewAttributeValueString(operation_typeAttributeValue))
}

// RecordElasticsearchNodeOperationsTimeDataPoint adds a data point to elasticsearch.node.operations.time metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeOperationsTimeDataPoint(ts pdata.Timestamp, val int64, operation_typeAttributeValue string) {
	if !mb.config.ElasticsearchNodeOperationsTime.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeOperationsTime.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.OperationType, pdata.NewAttributeValueString(operation_typeAttributeValue))
}

// RecordElasticsearchNodeShardsSizeDataPoint adds a data point to elasticsearch.node.shards.size metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeShardsSizeDataPoint(ts pdata.Timestamp, val int64) {
	if !mb.config.ElasticsearchNodeShardsSize.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeShardsSize.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// RecordElasticsearchNodeThreadPoolFinishedTasksDataPoint adds a data point to elasticsearch.node.thread_pool.finished_tasks metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeThreadPoolFinishedTasksDataPoint(ts pdata.Timestamp, val int64, thread_pool_nameAttributeValue string, task_stateAttributeValue string) {
	if !mb.config.ElasticsearchNodeThreadPoolFinishedTasks.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeThreadPoolFinishedTasks.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.ThreadPoolName, pdata.NewAttributeValueString(thread_pool_nameAttributeValue))
	dp.Attributes().Insert(A.TaskState, pdata.NewAttributeValueString(task_stateAttributeValue))
}

// RecordElasticsearchNodeThreadPoolQueuedTasksDataPoint adds a data point to elasticsearch.node.thread_pool.queued_tasks metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeThreadPoolQueuedTasksDataPoint(ts pdata.Timestamp, val int64, thread_pool_nameAttributeValue string) {
	if !mb.config.ElasticsearchNodeThreadPoolQueuedTasks.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeThreadPoolQueuedTasks.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.ThreadPoolName, pdata.NewAttributeValueString(thread_pool_nameAttributeValue))
}

// RecordElasticsearchNodeThreadPoolThreadsDataPoint adds a data point to elasticsearch.node.thread_pool.threads metric.
// Any attribute of AttributeValueTypeEmpty type will be skipped.
func (mb *MetricsBuilder) RecordElasticsearchNodeThreadPoolThreadsDataPoint(ts pdata.Timestamp, val int64, thread_stateAttributeValue string) {
	if !mb.config.ElasticsearchNodeThreadPoolThreads.Enabled {
		return
	}

	dp := mb.metrics.elasticsearchNodeThreadPoolThreads.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(mb.startTime)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.ThreadState, pdata.NewAttributeValueString(thread_stateAttributeValue))
}

// Attributes contains the possible metric attributes that can be used.
var Attributes = struct {
	// CacheName (Type of cache)
	CacheName string
	// Direction (Data direction)
	Direction string
	// DocumentType (Type of document)
	DocumentType string
	// ElasticsearchClusterName (The name of the elasticsearch cluster)
	ElasticsearchClusterName string
	// ElasticsearchNodeName (The name of the elasticsearch node)
	ElasticsearchNodeName string
	// FsOperationType (Type of file store operation)
	FsOperationType string
	// GcType (Type of garbage collection)
	GcType string
	// MemoryType (Type of memory)
	MemoryType string
	// OperationType (Type of operation)
	OperationType string
	// ShardType (State of the shard)
	ShardType string
	// TaskState (State of the task_state)
	TaskState string
	// ThreadPoolName (Thread pool name)
	ThreadPoolName string
	// ThreadState (State of the thread)
	ThreadState string
}{
	"cache_name",
	"direction",
	"document_type",
	"elasticsearch.cluster.name",
	"elasticsearch.node.name",
	"fs_operation_type",
	"gc_type",
	"memory_type",
	"operation_type",
	"shard_type",
	"task_state",
	"thread_pool_name",
	"thread_state",
}

// A is an alias for Attributes.
var A = Attributes

// AttributeCacheName are the possible values that the attribute "cache_name" can have.
var AttributeCacheName = struct {
	Fielddata string
	Query     string
}{
	"fielddata",
	"query",
}

// AttributeDirection are the possible values that the attribute "direction" can have.
var AttributeDirection = struct {
	Received string
	Sent     string
}{
	"received",
	"sent",
}

// AttributeDocumentType are the possible values that the attribute "document_type" can have.
var AttributeDocumentType = struct {
	Active  string
	Deleted string
}{
	"active",
	"deleted",
}

// AttributeFsOperationType are the possible values that the attribute "fs_operation_type" can have.
var AttributeFsOperationType = struct {
	Read  string
	Write string
}{
	"read",
	"write",
}

// AttributeGcType are the possible values that the attribute "gc_type" can have.
var AttributeGcType = struct {
	Young string
	Old   string
}{
	"young",
	"old",
}

// AttributeMemoryType are the possible values that the attribute "memory_type" can have.
var AttributeMemoryType = struct {
	Heap    string
	NonHeap string
}{
	"heap",
	"non-heap",
}

// AttributeOperationType are the possible values that the attribute "operation_type" can have.
var AttributeOperationType = struct {
	Index   string
	Delete  string
	Get     string
	Query   string
	Fetch   string
	Scroll  string
	Suggest string
	Merge   string
	Refresh string
	Flush   string
	Warmer  string
}{
	"index",
	"delete",
	"get",
	"query",
	"fetch",
	"scroll",
	"suggest",
	"merge",
	"refresh",
	"flush",
	"warmer",
}

// AttributeShardType are the possible values that the attribute "shard_type" can have.
var AttributeShardType = struct {
	Active       string
	Relocating   string
	Initializing string
	Unassigned   string
}{
	"active",
	"relocating",
	"initializing",
	"unassigned",
}

// AttributeTaskState are the possible values that the attribute "task_state" can have.
var AttributeTaskState = struct {
	Rejected  string
	Completed string
}{
	"rejected",
	"completed",
}

// AttributeThreadState are the possible values that the attribute "thread_state" can have.
var AttributeThreadState = struct {
	Active string
	Idle   string
}{
	"active",
	"idle",
}
