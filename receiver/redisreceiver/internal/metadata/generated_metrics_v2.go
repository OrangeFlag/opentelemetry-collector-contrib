// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"fmt"
	"time"

	"go.opentelemetry.io/collector/model/pdata"
)

// MetricSettings provides common settings for a particular metric.
type MetricSettings struct {
	Enabled bool `mapstructure:"enabled"`
}

// MetricsSettings provides settings for redisreceiver metrics.
type MetricsSettings struct {
	RedisClientsBlocked                    MetricSettings `mapstructure:"redis.clients.blocked"`
	RedisClientsConnected                  MetricSettings `mapstructure:"redis.clients.connected"`
	RedisClientsMaxInputBuffer             MetricSettings `mapstructure:"redis.clients.max_input_buffer"`
	RedisClientsMaxOutputBuffer            MetricSettings `mapstructure:"redis.clients.max_output_buffer"`
	RedisCommands                          MetricSettings `mapstructure:"redis.commands"`
	RedisCommandsProcessed                 MetricSettings `mapstructure:"redis.commands.processed"`
	RedisConnectionsReceived               MetricSettings `mapstructure:"redis.connections.received"`
	RedisConnectionsRejected               MetricSettings `mapstructure:"redis.connections.rejected"`
	RedisCPUTime                           MetricSettings `mapstructure:"redis.cpu.time"`
	RedisDbAvgTTL                          MetricSettings `mapstructure:"redis.db.avg_ttl"`
	RedisDbExpires                         MetricSettings `mapstructure:"redis.db.expires"`
	RedisDbKeys                            MetricSettings `mapstructure:"redis.db.keys"`
	RedisKeysEvicted                       MetricSettings `mapstructure:"redis.keys.evicted"`
	RedisKeysExpired                       MetricSettings `mapstructure:"redis.keys.expired"`
	RedisKeyspaceHits                      MetricSettings `mapstructure:"redis.keyspace.hits"`
	RedisKeyspaceMisses                    MetricSettings `mapstructure:"redis.keyspace.misses"`
	RedisLatestFork                        MetricSettings `mapstructure:"redis.latest_fork"`
	RedisMemoryFragmentationRatio          MetricSettings `mapstructure:"redis.memory.fragmentation_ratio"`
	RedisMemoryLua                         MetricSettings `mapstructure:"redis.memory.lua"`
	RedisMemoryPeak                        MetricSettings `mapstructure:"redis.memory.peak"`
	RedisMemoryRss                         MetricSettings `mapstructure:"redis.memory.rss"`
	RedisMemoryUsed                        MetricSettings `mapstructure:"redis.memory.used"`
	RedisNetInput                          MetricSettings `mapstructure:"redis.net.input"`
	RedisNetOutput                         MetricSettings `mapstructure:"redis.net.output"`
	RedisRdbChangesSinceLastSave           MetricSettings `mapstructure:"redis.rdb.changes_since_last_save"`
	RedisReplicationBacklogFirstByteOffset MetricSettings `mapstructure:"redis.replication.backlog_first_byte_offset"`
	RedisReplicationOffset                 MetricSettings `mapstructure:"redis.replication.offset"`
	RedisSlavesConnected                   MetricSettings `mapstructure:"redis.slaves.connected"`
	RedisUptime                            MetricSettings `mapstructure:"redis.uptime"`
}

func DefaultMetricsSettings() MetricsSettings {
	return MetricsSettings{
		RedisClientsBlocked: MetricSettings{
			Enabled: true,
		},
		RedisClientsConnected: MetricSettings{
			Enabled: true,
		},
		RedisClientsMaxInputBuffer: MetricSettings{
			Enabled: true,
		},
		RedisClientsMaxOutputBuffer: MetricSettings{
			Enabled: true,
		},
		RedisCommands: MetricSettings{
			Enabled: true,
		},
		RedisCommandsProcessed: MetricSettings{
			Enabled: true,
		},
		RedisConnectionsReceived: MetricSettings{
			Enabled: true,
		},
		RedisConnectionsRejected: MetricSettings{
			Enabled: true,
		},
		RedisCPUTime: MetricSettings{
			Enabled: true,
		},
		RedisDbAvgTTL: MetricSettings{
			Enabled: true,
		},
		RedisDbExpires: MetricSettings{
			Enabled: true,
		},
		RedisDbKeys: MetricSettings{
			Enabled: true,
		},
		RedisKeysEvicted: MetricSettings{
			Enabled: true,
		},
		RedisKeysExpired: MetricSettings{
			Enabled: true,
		},
		RedisKeyspaceHits: MetricSettings{
			Enabled: true,
		},
		RedisKeyspaceMisses: MetricSettings{
			Enabled: true,
		},
		RedisLatestFork: MetricSettings{
			Enabled: true,
		},
		RedisMemoryFragmentationRatio: MetricSettings{
			Enabled: true,
		},
		RedisMemoryLua: MetricSettings{
			Enabled: true,
		},
		RedisMemoryPeak: MetricSettings{
			Enabled: true,
		},
		RedisMemoryRss: MetricSettings{
			Enabled: true,
		},
		RedisMemoryUsed: MetricSettings{
			Enabled: true,
		},
		RedisNetInput: MetricSettings{
			Enabled: true,
		},
		RedisNetOutput: MetricSettings{
			Enabled: true,
		},
		RedisRdbChangesSinceLastSave: MetricSettings{
			Enabled: true,
		},
		RedisReplicationBacklogFirstByteOffset: MetricSettings{
			Enabled: true,
		},
		RedisReplicationOffset: MetricSettings{
			Enabled: true,
		},
		RedisSlavesConnected: MetricSettings{
			Enabled: true,
		},
		RedisUptime: MetricSettings{
			Enabled: true,
		},
	}
}

type MetricIntf interface {
	GetName() string
	GetDescription() string
	GetUnit() string
	GetMetricType() MetricDataTypeMetadata
}

type MetricDataTypeMetadata struct {
	Sum   *Sum   `yaml:"sum"`
	Gauge *Gauge `yaml:"gauge"`
}

type Gauge struct {
	ValueType string
}

type Sum struct {
	Aggregation pdata.MetricAggregationTemporality
	Monotonic   bool
	ValueType   string
}

type metricRedisClientsBlocked struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.clients.blocked metric with initial data.
func (m *metricRedisClientsBlocked) init() {
	m.data.SetName("redis.clients.blocked")
	m.data.SetDescription("Number of clients pending on a blocking call")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

type MetricMetadataRedisClientsBlocked struct{}

func (m MetricMetadataRedisClientsBlocked) GetName() string {
	return "redis.clients.blocked"
}

func (m MetricMetadataRedisClientsBlocked) GetDescription() string {
	return "Number of clients pending on a blocking call"
}

func (m MetricMetadataRedisClientsBlocked) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisClientsBlocked) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisClientsBlocked) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   false,
			ValueType:   "Int",
		},
	}
}

func (m *metricRedisClientsBlocked) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClientsBlocked) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClientsBlocked) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClientsBlocked(settings MetricSettings) metricRedisClientsBlocked {
	m := metricRedisClientsBlocked{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClientsConnected struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.clients.connected metric with initial data.
func (m *metricRedisClientsConnected) init() {
	m.data.SetName("redis.clients.connected")
	m.data.SetDescription("Number of client connections (excluding connections from replicas)")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

type MetricMetadataRedisClientsConnected struct{}

func (m MetricMetadataRedisClientsConnected) GetName() string {
	return "redis.clients.connected"
}

func (m MetricMetadataRedisClientsConnected) GetDescription() string {
	return "Number of client connections (excluding connections from replicas)"
}

func (m MetricMetadataRedisClientsConnected) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisClientsConnected) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisClientsConnected) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   false,
			ValueType:   "Int",
		},
	}
}

func (m *metricRedisClientsConnected) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClientsConnected) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClientsConnected) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClientsConnected(settings MetricSettings) metricRedisClientsConnected {
	m := metricRedisClientsConnected{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClientsMaxInputBuffer struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.clients.max_input_buffer metric with initial data.
func (m *metricRedisClientsMaxInputBuffer) init() {
	m.data.SetName("redis.clients.max_input_buffer")
	m.data.SetDescription("Biggest input buffer among current client connections")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeGauge)
}

type MetricMetadataRedisClientsMaxInputBuffer struct{}

func (m MetricMetadataRedisClientsMaxInputBuffer) GetName() string {
	return "redis.clients.max_input_buffer"
}

func (m MetricMetadataRedisClientsMaxInputBuffer) GetDescription() string {
	return "Biggest input buffer among current client connections"
}

func (m MetricMetadataRedisClientsMaxInputBuffer) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisClientsMaxInputBuffer) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisClientsMaxInputBuffer) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Gauge: &Gauge{
			ValueType: "Int",
		},
	}
}

func (m *metricRedisClientsMaxInputBuffer) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClientsMaxInputBuffer) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClientsMaxInputBuffer) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClientsMaxInputBuffer(settings MetricSettings) metricRedisClientsMaxInputBuffer {
	m := metricRedisClientsMaxInputBuffer{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClientsMaxOutputBuffer struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.clients.max_output_buffer metric with initial data.
func (m *metricRedisClientsMaxOutputBuffer) init() {
	m.data.SetName("redis.clients.max_output_buffer")
	m.data.SetDescription("Longest output list among current client connections")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeGauge)
}

type MetricMetadataRedisClientsMaxOutputBuffer struct{}

func (m MetricMetadataRedisClientsMaxOutputBuffer) GetName() string {
	return "redis.clients.max_output_buffer"
}

func (m MetricMetadataRedisClientsMaxOutputBuffer) GetDescription() string {
	return "Longest output list among current client connections"
}

func (m MetricMetadataRedisClientsMaxOutputBuffer) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisClientsMaxOutputBuffer) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisClientsMaxOutputBuffer) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Gauge: &Gauge{
			ValueType: "Int",
		},
	}
}

func (m *metricRedisClientsMaxOutputBuffer) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClientsMaxOutputBuffer) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClientsMaxOutputBuffer) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClientsMaxOutputBuffer(settings MetricSettings) metricRedisClientsMaxOutputBuffer {
	m := metricRedisClientsMaxOutputBuffer{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisCommands struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.commands metric with initial data.
func (m *metricRedisCommands) init() {
	m.data.SetName("redis.commands")
	m.data.SetDescription("Number of commands processed per second")
	m.data.SetUnit("{ops}/s")
	m.data.SetDataType(pdata.MetricDataTypeGauge)
}

type MetricMetadataRedisCommands struct{}

func (m MetricMetadataRedisCommands) GetName() string {
	return "redis.commands"
}

func (m MetricMetadataRedisCommands) GetDescription() string {
	return "Number of commands processed per second"
}

func (m MetricMetadataRedisCommands) GetUnit() string {
	return "{ops}/s"
}

func (m MetricMetadataRedisCommands) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisCommands) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Gauge: &Gauge{
			ValueType: "Int",
		},
	}
}

func (m *metricRedisCommands) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisCommands) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisCommands) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisCommands(settings MetricSettings) metricRedisCommands {
	m := metricRedisCommands{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisCommandsProcessed struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.commands.processed metric with initial data.
func (m *metricRedisCommandsProcessed) init() {
	m.data.SetName("redis.commands.processed")
	m.data.SetDescription("Total number of commands processed by the server")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

type MetricMetadataRedisCommandsProcessed struct{}

func (m MetricMetadataRedisCommandsProcessed) GetName() string {
	return "redis.commands.processed"
}

func (m MetricMetadataRedisCommandsProcessed) GetDescription() string {
	return "Total number of commands processed by the server"
}

func (m MetricMetadataRedisCommandsProcessed) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisCommandsProcessed) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisCommandsProcessed) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   true,
			ValueType:   "Int",
		},
	}
}

func (m *metricRedisCommandsProcessed) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisCommandsProcessed) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisCommandsProcessed) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisCommandsProcessed(settings MetricSettings) metricRedisCommandsProcessed {
	m := metricRedisCommandsProcessed{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisConnectionsReceived struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.connections.received metric with initial data.
func (m *metricRedisConnectionsReceived) init() {
	m.data.SetName("redis.connections.received")
	m.data.SetDescription("Total number of connections accepted by the server")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

type MetricMetadataRedisConnectionsReceived struct{}

func (m MetricMetadataRedisConnectionsReceived) GetName() string {
	return "redis.connections.received"
}

func (m MetricMetadataRedisConnectionsReceived) GetDescription() string {
	return "Total number of connections accepted by the server"
}

func (m MetricMetadataRedisConnectionsReceived) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisConnectionsReceived) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisConnectionsReceived) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   true,
			ValueType:   "Int",
		},
	}
}

func (m *metricRedisConnectionsReceived) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisConnectionsReceived) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisConnectionsReceived) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisConnectionsReceived(settings MetricSettings) metricRedisConnectionsReceived {
	m := metricRedisConnectionsReceived{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisConnectionsRejected struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.connections.rejected metric with initial data.
func (m *metricRedisConnectionsRejected) init() {
	m.data.SetName("redis.connections.rejected")
	m.data.SetDescription("Number of connections rejected because of maxclients limit")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

type MetricMetadataRedisConnectionsRejected struct{}

func (m MetricMetadataRedisConnectionsRejected) GetName() string {
	return "redis.connections.rejected"
}

func (m MetricMetadataRedisConnectionsRejected) GetDescription() string {
	return "Number of connections rejected because of maxclients limit"
}

func (m MetricMetadataRedisConnectionsRejected) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisConnectionsRejected) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisConnectionsRejected) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   true,
			ValueType:   "Int",
		},
	}
}

func (m *metricRedisConnectionsRejected) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisConnectionsRejected) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisConnectionsRejected) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisConnectionsRejected(settings MetricSettings) metricRedisConnectionsRejected {
	m := metricRedisConnectionsRejected{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisCPUTime struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cpu.time metric with initial data.
func (m *metricRedisCPUTime) init() {
	m.data.SetName("redis.cpu.time")
	m.data.SetDescription("System CPU consumed by the Redis server in seconds since server start")
	m.data.SetUnit("s")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

type MetricMetadataRedisCPUTime struct{}

func (m MetricMetadataRedisCPUTime) GetName() string {
	return "redis.cpu.time"
}

func (m MetricMetadataRedisCPUTime) GetDescription() string {
	return "System CPU consumed by the Redis server in seconds since server start"
}

func (m MetricMetadataRedisCPUTime) GetUnit() string {
	return "s"
}

func (m MetricMetadataRedisCPUTime) GetValueType() string {
	return "float64"
}

func (m MetricMetadataRedisCPUTime) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   true,
			ValueType:   "Double",
		},
	}
}

func (m *metricRedisCPUTime) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val float64, stateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleVal(val)
	dp.Attributes().Insert(A.State, pdata.NewValueString(stateAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisCPUTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisCPUTime) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisCPUTime(settings MetricSettings) metricRedisCPUTime {
	m := metricRedisCPUTime{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisDbAvgTTL struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.db.avg_ttl metric with initial data.
func (m *metricRedisDbAvgTTL) init() {
	m.data.SetName("redis.db.avg_ttl")
	m.data.SetDescription("Average keyspace keys TTL")
	m.data.SetUnit("ms")
	m.data.SetDataType(pdata.MetricDataTypeGauge)
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

type MetricMetadataRedisDbAvgTTL struct{}

func (m MetricMetadataRedisDbAvgTTL) GetName() string {
	return "redis.db.avg_ttl"
}

func (m MetricMetadataRedisDbAvgTTL) GetDescription() string {
	return "Average keyspace keys TTL"
}

func (m MetricMetadataRedisDbAvgTTL) GetUnit() string {
	return "ms"
}

func (m MetricMetadataRedisDbAvgTTL) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisDbAvgTTL) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Gauge: &Gauge{
			ValueType: "Int",
		},
	}
}

func (m *metricRedisDbAvgTTL) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, dbAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Db, pdata.NewValueString(dbAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisDbAvgTTL) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisDbAvgTTL) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisDbAvgTTL(settings MetricSettings) metricRedisDbAvgTTL {
	m := metricRedisDbAvgTTL{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisDbExpires struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.db.expires metric with initial data.
func (m *metricRedisDbExpires) init() {
	m.data.SetName("redis.db.expires")
	m.data.SetDescription("Number of keyspace keys with an expiration")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeGauge)
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

type MetricMetadataRedisDbExpires struct{}

func (m MetricMetadataRedisDbExpires) GetName() string {
	return "redis.db.expires"
}

func (m MetricMetadataRedisDbExpires) GetDescription() string {
	return "Number of keyspace keys with an expiration"
}

func (m MetricMetadataRedisDbExpires) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisDbExpires) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisDbExpires) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Gauge: &Gauge{
			ValueType: "Int",
		},
	}
}

func (m *metricRedisDbExpires) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, dbAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Db, pdata.NewValueString(dbAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisDbExpires) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisDbExpires) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisDbExpires(settings MetricSettings) metricRedisDbExpires {
	m := metricRedisDbExpires{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisDbKeys struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.db.keys metric with initial data.
func (m *metricRedisDbKeys) init() {
	m.data.SetName("redis.db.keys")
	m.data.SetDescription("Number of keyspace keys")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeGauge)
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

type MetricMetadataRedisDbKeys struct{}

func (m MetricMetadataRedisDbKeys) GetName() string {
	return "redis.db.keys"
}

func (m MetricMetadataRedisDbKeys) GetDescription() string {
	return "Number of keyspace keys"
}

func (m MetricMetadataRedisDbKeys) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisDbKeys) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisDbKeys) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Gauge: &Gauge{
			ValueType: "Int",
		},
	}
}

func (m *metricRedisDbKeys) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, dbAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Db, pdata.NewValueString(dbAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisDbKeys) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisDbKeys) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisDbKeys(settings MetricSettings) metricRedisDbKeys {
	m := metricRedisDbKeys{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisKeysEvicted struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.keys.evicted metric with initial data.
func (m *metricRedisKeysEvicted) init() {
	m.data.SetName("redis.keys.evicted")
	m.data.SetDescription("Number of evicted keys due to maxmemory limit")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

type MetricMetadataRedisKeysEvicted struct{}

func (m MetricMetadataRedisKeysEvicted) GetName() string {
	return "redis.keys.evicted"
}

func (m MetricMetadataRedisKeysEvicted) GetDescription() string {
	return "Number of evicted keys due to maxmemory limit"
}

func (m MetricMetadataRedisKeysEvicted) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisKeysEvicted) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisKeysEvicted) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   true,
			ValueType:   "Int",
		},
	}
}

func (m *metricRedisKeysEvicted) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisKeysEvicted) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisKeysEvicted) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisKeysEvicted(settings MetricSettings) metricRedisKeysEvicted {
	m := metricRedisKeysEvicted{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisKeysExpired struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.keys.expired metric with initial data.
func (m *metricRedisKeysExpired) init() {
	m.data.SetName("redis.keys.expired")
	m.data.SetDescription("Total number of key expiration events")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

type MetricMetadataRedisKeysExpired struct{}

func (m MetricMetadataRedisKeysExpired) GetName() string {
	return "redis.keys.expired"
}

func (m MetricMetadataRedisKeysExpired) GetDescription() string {
	return "Total number of key expiration events"
}

func (m MetricMetadataRedisKeysExpired) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisKeysExpired) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisKeysExpired) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   true,
			ValueType:   "Int",
		},
	}
}

func (m *metricRedisKeysExpired) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisKeysExpired) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisKeysExpired) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisKeysExpired(settings MetricSettings) metricRedisKeysExpired {
	m := metricRedisKeysExpired{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisKeyspaceHits struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.keyspace.hits metric with initial data.
func (m *metricRedisKeyspaceHits) init() {
	m.data.SetName("redis.keyspace.hits")
	m.data.SetDescription("Number of successful lookup of keys in the main dictionary")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

type MetricMetadataRedisKeyspaceHits struct{}

func (m MetricMetadataRedisKeyspaceHits) GetName() string {
	return "redis.keyspace.hits"
}

func (m MetricMetadataRedisKeyspaceHits) GetDescription() string {
	return "Number of successful lookup of keys in the main dictionary"
}

func (m MetricMetadataRedisKeyspaceHits) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisKeyspaceHits) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisKeyspaceHits) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   true,
			ValueType:   "Int",
		},
	}
}

func (m *metricRedisKeyspaceHits) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisKeyspaceHits) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisKeyspaceHits) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisKeyspaceHits(settings MetricSettings) metricRedisKeyspaceHits {
	m := metricRedisKeyspaceHits{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisKeyspaceMisses struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.keyspace.misses metric with initial data.
func (m *metricRedisKeyspaceMisses) init() {
	m.data.SetName("redis.keyspace.misses")
	m.data.SetDescription("Number of failed lookup of keys in the main dictionary")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

type MetricMetadataRedisKeyspaceMisses struct{}

func (m MetricMetadataRedisKeyspaceMisses) GetName() string {
	return "redis.keyspace.misses"
}

func (m MetricMetadataRedisKeyspaceMisses) GetDescription() string {
	return "Number of failed lookup of keys in the main dictionary"
}

func (m MetricMetadataRedisKeyspaceMisses) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisKeyspaceMisses) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisKeyspaceMisses) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   true,
			ValueType:   "Int",
		},
	}
}

func (m *metricRedisKeyspaceMisses) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisKeyspaceMisses) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisKeyspaceMisses) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisKeyspaceMisses(settings MetricSettings) metricRedisKeyspaceMisses {
	m := metricRedisKeyspaceMisses{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisLatestFork struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.latest_fork metric with initial data.
func (m *metricRedisLatestFork) init() {
	m.data.SetName("redis.latest_fork")
	m.data.SetDescription("Duration of the latest fork operation in microseconds")
	m.data.SetUnit("us")
	m.data.SetDataType(pdata.MetricDataTypeGauge)
}

type MetricMetadataRedisLatestFork struct{}

func (m MetricMetadataRedisLatestFork) GetName() string {
	return "redis.latest_fork"
}

func (m MetricMetadataRedisLatestFork) GetDescription() string {
	return "Duration of the latest fork operation in microseconds"
}

func (m MetricMetadataRedisLatestFork) GetUnit() string {
	return "us"
}

func (m MetricMetadataRedisLatestFork) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisLatestFork) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Gauge: &Gauge{
			ValueType: "Int",
		},
	}
}

func (m *metricRedisLatestFork) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisLatestFork) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisLatestFork) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisLatestFork(settings MetricSettings) metricRedisLatestFork {
	m := metricRedisLatestFork{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisMemoryFragmentationRatio struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.memory.fragmentation_ratio metric with initial data.
func (m *metricRedisMemoryFragmentationRatio) init() {
	m.data.SetName("redis.memory.fragmentation_ratio")
	m.data.SetDescription("Ratio between used_memory_rss and used_memory")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeGauge)
}

type MetricMetadataRedisMemoryFragmentationRatio struct{}

func (m MetricMetadataRedisMemoryFragmentationRatio) GetName() string {
	return "redis.memory.fragmentation_ratio"
}

func (m MetricMetadataRedisMemoryFragmentationRatio) GetDescription() string {
	return "Ratio between used_memory_rss and used_memory"
}

func (m MetricMetadataRedisMemoryFragmentationRatio) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisMemoryFragmentationRatio) GetValueType() string {
	return "float64"
}

func (m MetricMetadataRedisMemoryFragmentationRatio) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Gauge: &Gauge{
			ValueType: "Double",
		},
	}
}

func (m *metricRedisMemoryFragmentationRatio) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val float64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisMemoryFragmentationRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisMemoryFragmentationRatio) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisMemoryFragmentationRatio(settings MetricSettings) metricRedisMemoryFragmentationRatio {
	m := metricRedisMemoryFragmentationRatio{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisMemoryLua struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.memory.lua metric with initial data.
func (m *metricRedisMemoryLua) init() {
	m.data.SetName("redis.memory.lua")
	m.data.SetDescription("Number of bytes used by the Lua engine")
	m.data.SetUnit("By")
	m.data.SetDataType(pdata.MetricDataTypeGauge)
}

type MetricMetadataRedisMemoryLua struct{}

func (m MetricMetadataRedisMemoryLua) GetName() string {
	return "redis.memory.lua"
}

func (m MetricMetadataRedisMemoryLua) GetDescription() string {
	return "Number of bytes used by the Lua engine"
}

func (m MetricMetadataRedisMemoryLua) GetUnit() string {
	return "By"
}

func (m MetricMetadataRedisMemoryLua) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisMemoryLua) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Gauge: &Gauge{
			ValueType: "Int",
		},
	}
}

func (m *metricRedisMemoryLua) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisMemoryLua) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisMemoryLua) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisMemoryLua(settings MetricSettings) metricRedisMemoryLua {
	m := metricRedisMemoryLua{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisMemoryPeak struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.memory.peak metric with initial data.
func (m *metricRedisMemoryPeak) init() {
	m.data.SetName("redis.memory.peak")
	m.data.SetDescription("Peak memory consumed by Redis (in bytes)")
	m.data.SetUnit("By")
	m.data.SetDataType(pdata.MetricDataTypeGauge)
}

type MetricMetadataRedisMemoryPeak struct{}

func (m MetricMetadataRedisMemoryPeak) GetName() string {
	return "redis.memory.peak"
}

func (m MetricMetadataRedisMemoryPeak) GetDescription() string {
	return "Peak memory consumed by Redis (in bytes)"
}

func (m MetricMetadataRedisMemoryPeak) GetUnit() string {
	return "By"
}

func (m MetricMetadataRedisMemoryPeak) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisMemoryPeak) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Gauge: &Gauge{
			ValueType: "Int",
		},
	}
}

func (m *metricRedisMemoryPeak) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisMemoryPeak) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisMemoryPeak) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisMemoryPeak(settings MetricSettings) metricRedisMemoryPeak {
	m := metricRedisMemoryPeak{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisMemoryRss struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.memory.rss metric with initial data.
func (m *metricRedisMemoryRss) init() {
	m.data.SetName("redis.memory.rss")
	m.data.SetDescription("Number of bytes that Redis allocated as seen by the operating system")
	m.data.SetUnit("By")
	m.data.SetDataType(pdata.MetricDataTypeGauge)
}

type MetricMetadataRedisMemoryRss struct{}

func (m MetricMetadataRedisMemoryRss) GetName() string {
	return "redis.memory.rss"
}

func (m MetricMetadataRedisMemoryRss) GetDescription() string {
	return "Number of bytes that Redis allocated as seen by the operating system"
}

func (m MetricMetadataRedisMemoryRss) GetUnit() string {
	return "By"
}

func (m MetricMetadataRedisMemoryRss) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisMemoryRss) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Gauge: &Gauge{
			ValueType: "Int",
		},
	}
}

func (m *metricRedisMemoryRss) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisMemoryRss) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisMemoryRss) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisMemoryRss(settings MetricSettings) metricRedisMemoryRss {
	m := metricRedisMemoryRss{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisMemoryUsed struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.memory.used metric with initial data.
func (m *metricRedisMemoryUsed) init() {
	m.data.SetName("redis.memory.used")
	m.data.SetDescription("Total number of bytes allocated by Redis using its allocator")
	m.data.SetUnit("By")
	m.data.SetDataType(pdata.MetricDataTypeGauge)
}

type MetricMetadataRedisMemoryUsed struct{}

func (m MetricMetadataRedisMemoryUsed) GetName() string {
	return "redis.memory.used"
}

func (m MetricMetadataRedisMemoryUsed) GetDescription() string {
	return "Total number of bytes allocated by Redis using its allocator"
}

func (m MetricMetadataRedisMemoryUsed) GetUnit() string {
	return "By"
}

func (m MetricMetadataRedisMemoryUsed) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisMemoryUsed) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Gauge: &Gauge{
			ValueType: "Int",
		},
	}
}

func (m *metricRedisMemoryUsed) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisMemoryUsed) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisMemoryUsed) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisMemoryUsed(settings MetricSettings) metricRedisMemoryUsed {
	m := metricRedisMemoryUsed{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisNetInput struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.net.input metric with initial data.
func (m *metricRedisNetInput) init() {
	m.data.SetName("redis.net.input")
	m.data.SetDescription("The total number of bytes read from the network")
	m.data.SetUnit("By")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

type MetricMetadataRedisNetInput struct{}

func (m MetricMetadataRedisNetInput) GetName() string {
	return "redis.net.input"
}

func (m MetricMetadataRedisNetInput) GetDescription() string {
	return "The total number of bytes read from the network"
}

func (m MetricMetadataRedisNetInput) GetUnit() string {
	return "By"
}

func (m MetricMetadataRedisNetInput) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisNetInput) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   true,
			ValueType:   "Int",
		},
	}
}

func (m *metricRedisNetInput) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisNetInput) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisNetInput) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisNetInput(settings MetricSettings) metricRedisNetInput {
	m := metricRedisNetInput{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisNetOutput struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.net.output metric with initial data.
func (m *metricRedisNetOutput) init() {
	m.data.SetName("redis.net.output")
	m.data.SetDescription("The total number of bytes written to the network")
	m.data.SetUnit("By")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

type MetricMetadataRedisNetOutput struct{}

func (m MetricMetadataRedisNetOutput) GetName() string {
	return "redis.net.output"
}

func (m MetricMetadataRedisNetOutput) GetDescription() string {
	return "The total number of bytes written to the network"
}

func (m MetricMetadataRedisNetOutput) GetUnit() string {
	return "By"
}

func (m MetricMetadataRedisNetOutput) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisNetOutput) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   true,
			ValueType:   "Int",
		},
	}
}

func (m *metricRedisNetOutput) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisNetOutput) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisNetOutput) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisNetOutput(settings MetricSettings) metricRedisNetOutput {
	m := metricRedisNetOutput{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisRdbChangesSinceLastSave struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.rdb.changes_since_last_save metric with initial data.
func (m *metricRedisRdbChangesSinceLastSave) init() {
	m.data.SetName("redis.rdb.changes_since_last_save")
	m.data.SetDescription("Number of changes since the last dump")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

type MetricMetadataRedisRdbChangesSinceLastSave struct{}

func (m MetricMetadataRedisRdbChangesSinceLastSave) GetName() string {
	return "redis.rdb.changes_since_last_save"
}

func (m MetricMetadataRedisRdbChangesSinceLastSave) GetDescription() string {
	return "Number of changes since the last dump"
}

func (m MetricMetadataRedisRdbChangesSinceLastSave) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisRdbChangesSinceLastSave) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisRdbChangesSinceLastSave) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   false,
			ValueType:   "Int",
		},
	}
}

func (m *metricRedisRdbChangesSinceLastSave) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisRdbChangesSinceLastSave) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisRdbChangesSinceLastSave) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisRdbChangesSinceLastSave(settings MetricSettings) metricRedisRdbChangesSinceLastSave {
	m := metricRedisRdbChangesSinceLastSave{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisReplicationBacklogFirstByteOffset struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.replication.backlog_first_byte_offset metric with initial data.
func (m *metricRedisReplicationBacklogFirstByteOffset) init() {
	m.data.SetName("redis.replication.backlog_first_byte_offset")
	m.data.SetDescription("The master offset of the replication backlog buffer")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeGauge)
}

type MetricMetadataRedisReplicationBacklogFirstByteOffset struct{}

func (m MetricMetadataRedisReplicationBacklogFirstByteOffset) GetName() string {
	return "redis.replication.backlog_first_byte_offset"
}

func (m MetricMetadataRedisReplicationBacklogFirstByteOffset) GetDescription() string {
	return "The master offset of the replication backlog buffer"
}

func (m MetricMetadataRedisReplicationBacklogFirstByteOffset) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisReplicationBacklogFirstByteOffset) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisReplicationBacklogFirstByteOffset) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Gauge: &Gauge{
			ValueType: "Int",
		},
	}
}

func (m *metricRedisReplicationBacklogFirstByteOffset) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisReplicationBacklogFirstByteOffset) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisReplicationBacklogFirstByteOffset) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisReplicationBacklogFirstByteOffset(settings MetricSettings) metricRedisReplicationBacklogFirstByteOffset {
	m := metricRedisReplicationBacklogFirstByteOffset{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisReplicationOffset struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.replication.offset metric with initial data.
func (m *metricRedisReplicationOffset) init() {
	m.data.SetName("redis.replication.offset")
	m.data.SetDescription("The server's current replication offset")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeGauge)
}

type MetricMetadataRedisReplicationOffset struct{}

func (m MetricMetadataRedisReplicationOffset) GetName() string {
	return "redis.replication.offset"
}

func (m MetricMetadataRedisReplicationOffset) GetDescription() string {
	return "The server's current replication offset"
}

func (m MetricMetadataRedisReplicationOffset) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisReplicationOffset) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisReplicationOffset) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Gauge: &Gauge{
			ValueType: "Int",
		},
	}
}

func (m *metricRedisReplicationOffset) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisReplicationOffset) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisReplicationOffset) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisReplicationOffset(settings MetricSettings) metricRedisReplicationOffset {
	m := metricRedisReplicationOffset{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisSlavesConnected struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.slaves.connected metric with initial data.
func (m *metricRedisSlavesConnected) init() {
	m.data.SetName("redis.slaves.connected")
	m.data.SetDescription("Number of connected replicas")
	m.data.SetUnit("")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

type MetricMetadataRedisSlavesConnected struct{}

func (m MetricMetadataRedisSlavesConnected) GetName() string {
	return "redis.slaves.connected"
}

func (m MetricMetadataRedisSlavesConnected) GetDescription() string {
	return "Number of connected replicas"
}

func (m MetricMetadataRedisSlavesConnected) GetUnit() string {
	return ""
}

func (m MetricMetadataRedisSlavesConnected) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisSlavesConnected) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   false,
			ValueType:   "Int",
		},
	}
}

func (m *metricRedisSlavesConnected) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisSlavesConnected) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisSlavesConnected) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisSlavesConnected(settings MetricSettings) metricRedisSlavesConnected {
	m := metricRedisSlavesConnected{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricRedisUptime struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.uptime metric with initial data.
func (m *metricRedisUptime) init() {
	m.data.SetName("redis.uptime")
	m.data.SetDescription("Number of seconds since Redis server start")
	m.data.SetUnit("s")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

type MetricMetadataRedisUptime struct{}

func (m MetricMetadataRedisUptime) GetName() string {
	return "redis.uptime"
}

func (m MetricMetadataRedisUptime) GetDescription() string {
	return "Number of seconds since Redis server start"
}

func (m MetricMetadataRedisUptime) GetUnit() string {
	return "s"
}

func (m MetricMetadataRedisUptime) GetValueType() string {
	return "int64"
}

func (m MetricMetadataRedisUptime) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   true,
			ValueType:   "Int",
		},
	}
}

func (m *metricRedisUptime) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisUptime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisUptime) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisUptime(settings MetricSettings) metricRedisUptime {
	m := metricRedisUptime{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user settings.
type MetricsBuilder struct {
	startTime                                    pdata.Timestamp // start time that will be applied to all recorded data points.
	metricsCapacity                              int             // maximum observed number of metrics per resource.
	resourceCapacity                             int             // maximum observed number of resource attributes.
	metricsBuffer                                pdata.Metrics   // accumulates metrics data before emitting.
	metricRedisClientsBlocked                    metricRedisClientsBlocked
	metricRedisClientsConnected                  metricRedisClientsConnected
	metricRedisClientsMaxInputBuffer             metricRedisClientsMaxInputBuffer
	metricRedisClientsMaxOutputBuffer            metricRedisClientsMaxOutputBuffer
	metricRedisCommands                          metricRedisCommands
	metricRedisCommandsProcessed                 metricRedisCommandsProcessed
	metricRedisConnectionsReceived               metricRedisConnectionsReceived
	metricRedisConnectionsRejected               metricRedisConnectionsRejected
	metricRedisCPUTime                           metricRedisCPUTime
	metricRedisDbAvgTTL                          metricRedisDbAvgTTL
	metricRedisDbExpires                         metricRedisDbExpires
	metricRedisDbKeys                            metricRedisDbKeys
	metricRedisKeysEvicted                       metricRedisKeysEvicted
	metricRedisKeysExpired                       metricRedisKeysExpired
	metricRedisKeyspaceHits                      metricRedisKeyspaceHits
	metricRedisKeyspaceMisses                    metricRedisKeyspaceMisses
	metricRedisLatestFork                        metricRedisLatestFork
	metricRedisMemoryFragmentationRatio          metricRedisMemoryFragmentationRatio
	metricRedisMemoryLua                         metricRedisMemoryLua
	metricRedisMemoryPeak                        metricRedisMemoryPeak
	metricRedisMemoryRss                         metricRedisMemoryRss
	metricRedisMemoryUsed                        metricRedisMemoryUsed
	metricRedisNetInput                          metricRedisNetInput
	metricRedisNetOutput                         metricRedisNetOutput
	metricRedisRdbChangesSinceLastSave           metricRedisRdbChangesSinceLastSave
	metricRedisReplicationBacklogFirstByteOffset metricRedisReplicationBacklogFirstByteOffset
	metricRedisReplicationOffset                 metricRedisReplicationOffset
	metricRedisSlavesConnected                   metricRedisSlavesConnected
	metricRedisUptime                            metricRedisUptime
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pdata.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(settings MetricsSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		startTime:                                    pdata.NewTimestampFromTime(time.Now()),
		metricsBuffer:                                pdata.NewMetrics(),
		metricRedisClientsBlocked:                    newMetricRedisClientsBlocked(settings.RedisClientsBlocked),
		metricRedisClientsConnected:                  newMetricRedisClientsConnected(settings.RedisClientsConnected),
		metricRedisClientsMaxInputBuffer:             newMetricRedisClientsMaxInputBuffer(settings.RedisClientsMaxInputBuffer),
		metricRedisClientsMaxOutputBuffer:            newMetricRedisClientsMaxOutputBuffer(settings.RedisClientsMaxOutputBuffer),
		metricRedisCommands:                          newMetricRedisCommands(settings.RedisCommands),
		metricRedisCommandsProcessed:                 newMetricRedisCommandsProcessed(settings.RedisCommandsProcessed),
		metricRedisConnectionsReceived:               newMetricRedisConnectionsReceived(settings.RedisConnectionsReceived),
		metricRedisConnectionsRejected:               newMetricRedisConnectionsRejected(settings.RedisConnectionsRejected),
		metricRedisCPUTime:                           newMetricRedisCPUTime(settings.RedisCPUTime),
		metricRedisDbAvgTTL:                          newMetricRedisDbAvgTTL(settings.RedisDbAvgTTL),
		metricRedisDbExpires:                         newMetricRedisDbExpires(settings.RedisDbExpires),
		metricRedisDbKeys:                            newMetricRedisDbKeys(settings.RedisDbKeys),
		metricRedisKeysEvicted:                       newMetricRedisKeysEvicted(settings.RedisKeysEvicted),
		metricRedisKeysExpired:                       newMetricRedisKeysExpired(settings.RedisKeysExpired),
		metricRedisKeyspaceHits:                      newMetricRedisKeyspaceHits(settings.RedisKeyspaceHits),
		metricRedisKeyspaceMisses:                    newMetricRedisKeyspaceMisses(settings.RedisKeyspaceMisses),
		metricRedisLatestFork:                        newMetricRedisLatestFork(settings.RedisLatestFork),
		metricRedisMemoryFragmentationRatio:          newMetricRedisMemoryFragmentationRatio(settings.RedisMemoryFragmentationRatio),
		metricRedisMemoryLua:                         newMetricRedisMemoryLua(settings.RedisMemoryLua),
		metricRedisMemoryPeak:                        newMetricRedisMemoryPeak(settings.RedisMemoryPeak),
		metricRedisMemoryRss:                         newMetricRedisMemoryRss(settings.RedisMemoryRss),
		metricRedisMemoryUsed:                        newMetricRedisMemoryUsed(settings.RedisMemoryUsed),
		metricRedisNetInput:                          newMetricRedisNetInput(settings.RedisNetInput),
		metricRedisNetOutput:                         newMetricRedisNetOutput(settings.RedisNetOutput),
		metricRedisRdbChangesSinceLastSave:           newMetricRedisRdbChangesSinceLastSave(settings.RedisRdbChangesSinceLastSave),
		metricRedisReplicationBacklogFirstByteOffset: newMetricRedisReplicationBacklogFirstByteOffset(settings.RedisReplicationBacklogFirstByteOffset),
		metricRedisReplicationOffset:                 newMetricRedisReplicationOffset(settings.RedisReplicationOffset),
		metricRedisSlavesConnected:                   newMetricRedisSlavesConnected(settings.RedisSlavesConnected),
		metricRedisUptime:                            newMetricRedisUptime(settings.RedisUptime),
	}
	for _, op := range options {
		op(mb)
	}
	return mb
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pdata.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
	if mb.resourceCapacity < rm.Resource().Attributes().Len() {
		mb.resourceCapacity = rm.Resource().Attributes().Len()
	}
}

// ResourceOption applies changes to provided resource.
type ResourceOption func(pdata.Resource)

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead. Resource attributes should be provided as ResourceOption arguments.
func (mb *MetricsBuilder) EmitForResource(ro ...ResourceOption) {
	rm := pdata.NewResourceMetrics()
	rm.Resource().Attributes().EnsureCapacity(mb.resourceCapacity)
	for _, op := range ro {
		op(rm.Resource())
	}
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName("otelcol/redisreceiver")
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricRedisClientsBlocked.emit(ils.Metrics())
	mb.metricRedisClientsConnected.emit(ils.Metrics())
	mb.metricRedisClientsMaxInputBuffer.emit(ils.Metrics())
	mb.metricRedisClientsMaxOutputBuffer.emit(ils.Metrics())
	mb.metricRedisCommands.emit(ils.Metrics())
	mb.metricRedisCommandsProcessed.emit(ils.Metrics())
	mb.metricRedisConnectionsReceived.emit(ils.Metrics())
	mb.metricRedisConnectionsRejected.emit(ils.Metrics())
	mb.metricRedisCPUTime.emit(ils.Metrics())
	mb.metricRedisDbAvgTTL.emit(ils.Metrics())
	mb.metricRedisDbExpires.emit(ils.Metrics())
	mb.metricRedisDbKeys.emit(ils.Metrics())
	mb.metricRedisKeysEvicted.emit(ils.Metrics())
	mb.metricRedisKeysExpired.emit(ils.Metrics())
	mb.metricRedisKeyspaceHits.emit(ils.Metrics())
	mb.metricRedisKeyspaceMisses.emit(ils.Metrics())
	mb.metricRedisLatestFork.emit(ils.Metrics())
	mb.metricRedisMemoryFragmentationRatio.emit(ils.Metrics())
	mb.metricRedisMemoryLua.emit(ils.Metrics())
	mb.metricRedisMemoryPeak.emit(ils.Metrics())
	mb.metricRedisMemoryRss.emit(ils.Metrics())
	mb.metricRedisMemoryUsed.emit(ils.Metrics())
	mb.metricRedisNetInput.emit(ils.Metrics())
	mb.metricRedisNetOutput.emit(ils.Metrics())
	mb.metricRedisRdbChangesSinceLastSave.emit(ils.Metrics())
	mb.metricRedisReplicationBacklogFirstByteOffset.emit(ils.Metrics())
	mb.metricRedisReplicationOffset.emit(ils.Metrics())
	mb.metricRedisSlavesConnected.emit(ils.Metrics())
	mb.metricRedisUptime.emit(ils.Metrics())
	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user settings, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(ro ...ResourceOption) pdata.Metrics {
	mb.EmitForResource(ro...)
	metrics := pdata.NewMetrics()
	mb.metricsBuffer.MoveTo(metrics)
	return metrics
}

// RecordRedisClientsBlockedDataPoint adds a data point to redis.clients.blocked metric.
func (mb *MetricsBuilder) RecordRedisClientsBlockedDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisClientsBlocked.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClientsConnectedDataPoint adds a data point to redis.clients.connected metric.
func (mb *MetricsBuilder) RecordRedisClientsConnectedDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisClientsConnected.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClientsMaxInputBufferDataPoint adds a data point to redis.clients.max_input_buffer metric.
func (mb *MetricsBuilder) RecordRedisClientsMaxInputBufferDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisClientsMaxInputBuffer.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClientsMaxOutputBufferDataPoint adds a data point to redis.clients.max_output_buffer metric.
func (mb *MetricsBuilder) RecordRedisClientsMaxOutputBufferDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisClientsMaxOutputBuffer.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisCommandsDataPoint adds a data point to redis.commands metric.
func (mb *MetricsBuilder) RecordRedisCommandsDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisCommands.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisCommandsProcessedDataPoint adds a data point to redis.commands.processed metric.
func (mb *MetricsBuilder) RecordRedisCommandsProcessedDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisCommandsProcessed.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisConnectionsReceivedDataPoint adds a data point to redis.connections.received metric.
func (mb *MetricsBuilder) RecordRedisConnectionsReceivedDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisConnectionsReceived.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisConnectionsRejectedDataPoint adds a data point to redis.connections.rejected metric.
func (mb *MetricsBuilder) RecordRedisConnectionsRejectedDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisConnectionsRejected.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisCPUTimeDataPoint adds a data point to redis.cpu.time metric.
func (mb *MetricsBuilder) RecordRedisCPUTimeDataPoint(ts pdata.Timestamp, val float64, stateAttributeValue string) {
	mb.metricRedisCPUTime.recordDataPoint(mb.startTime, ts, val, stateAttributeValue)
}

// RecordRedisDbAvgTTLDataPoint adds a data point to redis.db.avg_ttl metric.
func (mb *MetricsBuilder) RecordRedisDbAvgTTLDataPoint(ts pdata.Timestamp, val int64, dbAttributeValue string) {
	mb.metricRedisDbAvgTTL.recordDataPoint(mb.startTime, ts, val, dbAttributeValue)
}

// RecordRedisDbExpiresDataPoint adds a data point to redis.db.expires metric.
func (mb *MetricsBuilder) RecordRedisDbExpiresDataPoint(ts pdata.Timestamp, val int64, dbAttributeValue string) {
	mb.metricRedisDbExpires.recordDataPoint(mb.startTime, ts, val, dbAttributeValue)
}

// RecordRedisDbKeysDataPoint adds a data point to redis.db.keys metric.
func (mb *MetricsBuilder) RecordRedisDbKeysDataPoint(ts pdata.Timestamp, val int64, dbAttributeValue string) {
	mb.metricRedisDbKeys.recordDataPoint(mb.startTime, ts, val, dbAttributeValue)
}

// RecordRedisKeysEvictedDataPoint adds a data point to redis.keys.evicted metric.
func (mb *MetricsBuilder) RecordRedisKeysEvictedDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisKeysEvicted.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisKeysExpiredDataPoint adds a data point to redis.keys.expired metric.
func (mb *MetricsBuilder) RecordRedisKeysExpiredDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisKeysExpired.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisKeyspaceHitsDataPoint adds a data point to redis.keyspace.hits metric.
func (mb *MetricsBuilder) RecordRedisKeyspaceHitsDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisKeyspaceHits.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisKeyspaceMissesDataPoint adds a data point to redis.keyspace.misses metric.
func (mb *MetricsBuilder) RecordRedisKeyspaceMissesDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisKeyspaceMisses.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisLatestForkDataPoint adds a data point to redis.latest_fork metric.
func (mb *MetricsBuilder) RecordRedisLatestForkDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisLatestFork.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisMemoryFragmentationRatioDataPoint adds a data point to redis.memory.fragmentation_ratio metric.
func (mb *MetricsBuilder) RecordRedisMemoryFragmentationRatioDataPoint(ts pdata.Timestamp, val float64) {
	mb.metricRedisMemoryFragmentationRatio.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisMemoryLuaDataPoint adds a data point to redis.memory.lua metric.
func (mb *MetricsBuilder) RecordRedisMemoryLuaDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisMemoryLua.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisMemoryPeakDataPoint adds a data point to redis.memory.peak metric.
func (mb *MetricsBuilder) RecordRedisMemoryPeakDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisMemoryPeak.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisMemoryRssDataPoint adds a data point to redis.memory.rss metric.
func (mb *MetricsBuilder) RecordRedisMemoryRssDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisMemoryRss.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisMemoryUsedDataPoint adds a data point to redis.memory.used metric.
func (mb *MetricsBuilder) RecordRedisMemoryUsedDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisMemoryUsed.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisNetInputDataPoint adds a data point to redis.net.input metric.
func (mb *MetricsBuilder) RecordRedisNetInputDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisNetInput.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisNetOutputDataPoint adds a data point to redis.net.output metric.
func (mb *MetricsBuilder) RecordRedisNetOutputDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisNetOutput.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisRdbChangesSinceLastSaveDataPoint adds a data point to redis.rdb.changes_since_last_save metric.
func (mb *MetricsBuilder) RecordRedisRdbChangesSinceLastSaveDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisRdbChangesSinceLastSave.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisReplicationBacklogFirstByteOffsetDataPoint adds a data point to redis.replication.backlog_first_byte_offset metric.
func (mb *MetricsBuilder) RecordRedisReplicationBacklogFirstByteOffsetDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisReplicationBacklogFirstByteOffset.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisReplicationOffsetDataPoint adds a data point to redis.replication.offset metric.
func (mb *MetricsBuilder) RecordRedisReplicationOffsetDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisReplicationOffset.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisSlavesConnectedDataPoint adds a data point to redis.slaves.connected metric.
func (mb *MetricsBuilder) RecordRedisSlavesConnectedDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisSlavesConnected.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisUptimeDataPoint adds a data point to redis.uptime metric.
func (mb *MetricsBuilder) RecordRedisUptimeDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricRedisUptime.recordDataPoint(mb.startTime, ts, val)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...metricBuilderOption) {
	mb.startTime = pdata.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(mb)
	}
}

func (mb *MetricsBuilder) Record(metricName string, ts pdata.Timestamp, value interface{}, attributes ...string) error {
	switch metricName {

	case "redis.clients.blocked":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisClientsBlockedDataPoint(ts, intVal)
	case "redis.clients.connected":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisClientsConnectedDataPoint(ts, intVal)
	case "redis.clients.max_input_buffer":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisClientsMaxInputBufferDataPoint(ts, intVal)
	case "redis.clients.max_output_buffer":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisClientsMaxOutputBufferDataPoint(ts, intVal)
	case "redis.commands":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisCommandsDataPoint(ts, intVal)
	case "redis.commands.processed":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisCommandsProcessedDataPoint(ts, intVal)
	case "redis.connections.received":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisConnectionsReceivedDataPoint(ts, intVal)
	case "redis.connections.rejected":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisConnectionsRejectedDataPoint(ts, intVal)
	case "redis.cpu.time":
		floatVal, ok := value.(float64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisCPUTimeDataPoint(ts, floatVal, attributes[0])
	case "redis.db.avg_ttl":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisDbAvgTTLDataPoint(ts, intVal, attributes[0])
	case "redis.db.expires":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisDbExpiresDataPoint(ts, intVal, attributes[0])
	case "redis.db.keys":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisDbKeysDataPoint(ts, intVal, attributes[0])
	case "redis.keys.evicted":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisKeysEvictedDataPoint(ts, intVal)
	case "redis.keys.expired":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisKeysExpiredDataPoint(ts, intVal)
	case "redis.keyspace.hits":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisKeyspaceHitsDataPoint(ts, intVal)
	case "redis.keyspace.misses":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisKeyspaceMissesDataPoint(ts, intVal)
	case "redis.latest_fork":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisLatestForkDataPoint(ts, intVal)
	case "redis.memory.fragmentation_ratio":
		floatVal, ok := value.(float64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisMemoryFragmentationRatioDataPoint(ts, floatVal)
	case "redis.memory.lua":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisMemoryLuaDataPoint(ts, intVal)
	case "redis.memory.peak":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisMemoryPeakDataPoint(ts, intVal)
	case "redis.memory.rss":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisMemoryRssDataPoint(ts, intVal)
	case "redis.memory.used":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisMemoryUsedDataPoint(ts, intVal)
	case "redis.net.input":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisNetInputDataPoint(ts, intVal)
	case "redis.net.output":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisNetOutputDataPoint(ts, intVal)
	case "redis.rdb.changes_since_last_save":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisRdbChangesSinceLastSaveDataPoint(ts, intVal)
	case "redis.replication.backlog_first_byte_offset":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisReplicationBacklogFirstByteOffsetDataPoint(ts, intVal)
	case "redis.replication.offset":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisReplicationOffsetDataPoint(ts, intVal)
	case "redis.slaves.connected":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisSlavesConnectedDataPoint(ts, intVal)
	case "redis.uptime":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordRedisUptimeDataPoint(ts, intVal)
	}
	return nil
}

// Attributes contains the possible metric attributes that can be used.
var Attributes = struct {
	// Db (Redis database identifier)
	Db string
	// State (Redis CPU usage state)
	State string
}{
	"db",
	"state",
}

var metricsByName = map[string]MetricIntf{
	"redis.clients.blocked":                       MetricMetadataRedisClientsBlocked{},
	"redis.clients.connected":                     MetricMetadataRedisClientsConnected{},
	"redis.clients.max_input_buffer":              MetricMetadataRedisClientsMaxInputBuffer{},
	"redis.clients.max_output_buffer":             MetricMetadataRedisClientsMaxOutputBuffer{},
	"redis.commands":                              MetricMetadataRedisCommands{},
	"redis.commands.processed":                    MetricMetadataRedisCommandsProcessed{},
	"redis.connections.received":                  MetricMetadataRedisConnectionsReceived{},
	"redis.connections.rejected":                  MetricMetadataRedisConnectionsRejected{},
	"redis.cpu.time":                              MetricMetadataRedisCPUTime{},
	"redis.db.avg_ttl":                            MetricMetadataRedisDbAvgTTL{},
	"redis.db.expires":                            MetricMetadataRedisDbExpires{},
	"redis.db.keys":                               MetricMetadataRedisDbKeys{},
	"redis.keys.evicted":                          MetricMetadataRedisKeysEvicted{},
	"redis.keys.expired":                          MetricMetadataRedisKeysExpired{},
	"redis.keyspace.hits":                         MetricMetadataRedisKeyspaceHits{},
	"redis.keyspace.misses":                       MetricMetadataRedisKeyspaceMisses{},
	"redis.latest_fork":                           MetricMetadataRedisLatestFork{},
	"redis.memory.fragmentation_ratio":            MetricMetadataRedisMemoryFragmentationRatio{},
	"redis.memory.lua":                            MetricMetadataRedisMemoryLua{},
	"redis.memory.peak":                           MetricMetadataRedisMemoryPeak{},
	"redis.memory.rss":                            MetricMetadataRedisMemoryRss{},
	"redis.memory.used":                           MetricMetadataRedisMemoryUsed{},
	"redis.net.input":                             MetricMetadataRedisNetInput{},
	"redis.net.output":                            MetricMetadataRedisNetOutput{},
	"redis.rdb.changes_since_last_save":           MetricMetadataRedisRdbChangesSinceLastSave{},
	"redis.replication.backlog_first_byte_offset": MetricMetadataRedisReplicationBacklogFirstByteOffset{},
	"redis.replication.offset":                    MetricMetadataRedisReplicationOffset{},
	"redis.slaves.connected":                      MetricMetadataRedisSlavesConnected{},
	"redis.uptime":                                MetricMetadataRedisUptime{},
}

func EnabledMetrics(settings MetricsSettings) map[string]bool {
	return map[string]bool{
		"redis.clients.blocked":                       settings.RedisClientsBlocked.Enabled,
		"redis.clients.connected":                     settings.RedisClientsConnected.Enabled,
		"redis.clients.max_input_buffer":              settings.RedisClientsMaxInputBuffer.Enabled,
		"redis.clients.max_output_buffer":             settings.RedisClientsMaxOutputBuffer.Enabled,
		"redis.commands":                              settings.RedisCommands.Enabled,
		"redis.commands.processed":                    settings.RedisCommandsProcessed.Enabled,
		"redis.connections.received":                  settings.RedisConnectionsReceived.Enabled,
		"redis.connections.rejected":                  settings.RedisConnectionsRejected.Enabled,
		"redis.cpu.time":                              settings.RedisCPUTime.Enabled,
		"redis.db.avg_ttl":                            settings.RedisDbAvgTTL.Enabled,
		"redis.db.expires":                            settings.RedisDbExpires.Enabled,
		"redis.db.keys":                               settings.RedisDbKeys.Enabled,
		"redis.keys.evicted":                          settings.RedisKeysEvicted.Enabled,
		"redis.keys.expired":                          settings.RedisKeysExpired.Enabled,
		"redis.keyspace.hits":                         settings.RedisKeyspaceHits.Enabled,
		"redis.keyspace.misses":                       settings.RedisKeyspaceMisses.Enabled,
		"redis.latest_fork":                           settings.RedisLatestFork.Enabled,
		"redis.memory.fragmentation_ratio":            settings.RedisMemoryFragmentationRatio.Enabled,
		"redis.memory.lua":                            settings.RedisMemoryLua.Enabled,
		"redis.memory.peak":                           settings.RedisMemoryPeak.Enabled,
		"redis.memory.rss":                            settings.RedisMemoryRss.Enabled,
		"redis.memory.used":                           settings.RedisMemoryUsed.Enabled,
		"redis.net.input":                             settings.RedisNetInput.Enabled,
		"redis.net.output":                            settings.RedisNetOutput.Enabled,
		"redis.rdb.changes_since_last_save":           settings.RedisRdbChangesSinceLastSave.Enabled,
		"redis.replication.backlog_first_byte_offset": settings.RedisReplicationBacklogFirstByteOffset.Enabled,
		"redis.replication.offset":                    settings.RedisReplicationOffset.Enabled,
		"redis.slaves.connected":                      settings.RedisSlavesConnected.Enabled,
		"redis.uptime":                                settings.RedisUptime.Enabled,
	}
}

func ByName(n string) MetricIntf {
	return metricsByName[n]
}

// A is an alias for Attributes.
var A = Attributes
