// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"fmt"
	"time"

	"go.opentelemetry.io/collector/model/pdata"
)

// MetricSettings provides common settings for a particular metric.
type MetricSettings struct {
	Enabled bool `mapstructure:"enabled"`
}

// MetricsSettings provides settings for postgresqlreceiver metrics.
type MetricsSettings struct {
	PostgresqlBackends   MetricSettings `mapstructure:"postgresql.backends"`
	PostgresqlBlocksRead MetricSettings `mapstructure:"postgresql.blocks_read"`
	PostgresqlCommits    MetricSettings `mapstructure:"postgresql.commits"`
	PostgresqlDbSize     MetricSettings `mapstructure:"postgresql.db_size"`
	PostgresqlOperations MetricSettings `mapstructure:"postgresql.operations"`
	PostgresqlRollbacks  MetricSettings `mapstructure:"postgresql.rollbacks"`
	PostgresqlRows       MetricSettings `mapstructure:"postgresql.rows"`
}

func DefaultMetricsSettings() MetricsSettings {
	return MetricsSettings{
		PostgresqlBackends: MetricSettings{
			Enabled: true,
		},
		PostgresqlBlocksRead: MetricSettings{
			Enabled: true,
		},
		PostgresqlCommits: MetricSettings{
			Enabled: true,
		},
		PostgresqlDbSize: MetricSettings{
			Enabled: true,
		},
		PostgresqlOperations: MetricSettings{
			Enabled: true,
		},
		PostgresqlRollbacks: MetricSettings{
			Enabled: true,
		},
		PostgresqlRows: MetricSettings{
			Enabled: true,
		},
	}
}

type MetricIntf interface {
	GetName() string
	GetDescription() string
	GetUnit() string
	GetMetricType() MetricDataTypeMetadata
}

type MetricDataTypeMetadata struct {
	Sum   *Sum   `yaml:"sum"`
	Gauge *Gauge `yaml:"gauge"`
}

type Gauge struct {
	ValueType string
}

type Sum struct {
	Aggregation pdata.MetricAggregationTemporality
	Monotonic   bool
	ValueType   string
}

type metricPostgresqlBackends struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills postgresql.backends metric with initial data.
func (m *metricPostgresqlBackends) init() {
	m.data.SetName("postgresql.backends")
	m.data.SetDescription("The number of backends.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

type MetricMetadataPostgresqlBackends struct{}

func (m MetricMetadataPostgresqlBackends) GetName() string {
	return "postgresql.backends"
}

func (m MetricMetadataPostgresqlBackends) GetDescription() string {
	return "The number of backends."
}

func (m MetricMetadataPostgresqlBackends) GetUnit() string {
	return "1"
}

func (m MetricMetadataPostgresqlBackends) GetValueType() string {
	return "int64"
}

func (m MetricMetadataPostgresqlBackends) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   false,
			ValueType:   "Int",
		},
	}
}

func (m *metricPostgresqlBackends) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, databaseAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Database, pdata.NewValueString(databaseAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricPostgresqlBackends) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricPostgresqlBackends) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricPostgresqlBackends(settings MetricSettings) metricPostgresqlBackends {
	m := metricPostgresqlBackends{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricPostgresqlBlocksRead struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills postgresql.blocks_read metric with initial data.
func (m *metricPostgresqlBlocksRead) init() {
	m.data.SetName("postgresql.blocks_read")
	m.data.SetDescription("The number of blocks read.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

type MetricMetadataPostgresqlBlocksRead struct{}

func (m MetricMetadataPostgresqlBlocksRead) GetName() string {
	return "postgresql.blocks_read"
}

func (m MetricMetadataPostgresqlBlocksRead) GetDescription() string {
	return "The number of blocks read."
}

func (m MetricMetadataPostgresqlBlocksRead) GetUnit() string {
	return "1"
}

func (m MetricMetadataPostgresqlBlocksRead) GetValueType() string {
	return "int64"
}

func (m MetricMetadataPostgresqlBlocksRead) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   true,
			ValueType:   "Int",
		},
	}
}

func (m *metricPostgresqlBlocksRead) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, databaseAttributeValue string, tableAttributeValue string, sourceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Database, pdata.NewValueString(databaseAttributeValue))
	dp.Attributes().Insert(A.Table, pdata.NewValueString(tableAttributeValue))
	dp.Attributes().Insert(A.Source, pdata.NewValueString(sourceAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricPostgresqlBlocksRead) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricPostgresqlBlocksRead) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricPostgresqlBlocksRead(settings MetricSettings) metricPostgresqlBlocksRead {
	m := metricPostgresqlBlocksRead{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricPostgresqlCommits struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills postgresql.commits metric with initial data.
func (m *metricPostgresqlCommits) init() {
	m.data.SetName("postgresql.commits")
	m.data.SetDescription("The number of commits.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

type MetricMetadataPostgresqlCommits struct{}

func (m MetricMetadataPostgresqlCommits) GetName() string {
	return "postgresql.commits"
}

func (m MetricMetadataPostgresqlCommits) GetDescription() string {
	return "The number of commits."
}

func (m MetricMetadataPostgresqlCommits) GetUnit() string {
	return "1"
}

func (m MetricMetadataPostgresqlCommits) GetValueType() string {
	return "int64"
}

func (m MetricMetadataPostgresqlCommits) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   true,
			ValueType:   "Int",
		},
	}
}

func (m *metricPostgresqlCommits) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, databaseAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Database, pdata.NewValueString(databaseAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricPostgresqlCommits) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricPostgresqlCommits) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricPostgresqlCommits(settings MetricSettings) metricPostgresqlCommits {
	m := metricPostgresqlCommits{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricPostgresqlDbSize struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills postgresql.db_size metric with initial data.
func (m *metricPostgresqlDbSize) init() {
	m.data.SetName("postgresql.db_size")
	m.data.SetDescription("The database disk usage.")
	m.data.SetUnit("By")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

type MetricMetadataPostgresqlDbSize struct{}

func (m MetricMetadataPostgresqlDbSize) GetName() string {
	return "postgresql.db_size"
}

func (m MetricMetadataPostgresqlDbSize) GetDescription() string {
	return "The database disk usage."
}

func (m MetricMetadataPostgresqlDbSize) GetUnit() string {
	return "By"
}

func (m MetricMetadataPostgresqlDbSize) GetValueType() string {
	return "int64"
}

func (m MetricMetadataPostgresqlDbSize) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   false,
			ValueType:   "Int",
		},
	}
}

func (m *metricPostgresqlDbSize) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, databaseAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Database, pdata.NewValueString(databaseAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricPostgresqlDbSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricPostgresqlDbSize) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricPostgresqlDbSize(settings MetricSettings) metricPostgresqlDbSize {
	m := metricPostgresqlDbSize{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricPostgresqlOperations struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills postgresql.operations metric with initial data.
func (m *metricPostgresqlOperations) init() {
	m.data.SetName("postgresql.operations")
	m.data.SetDescription("The number of db row operations.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

type MetricMetadataPostgresqlOperations struct{}

func (m MetricMetadataPostgresqlOperations) GetName() string {
	return "postgresql.operations"
}

func (m MetricMetadataPostgresqlOperations) GetDescription() string {
	return "The number of db row operations."
}

func (m MetricMetadataPostgresqlOperations) GetUnit() string {
	return "1"
}

func (m MetricMetadataPostgresqlOperations) GetValueType() string {
	return "int64"
}

func (m MetricMetadataPostgresqlOperations) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   true,
			ValueType:   "Int",
		},
	}
}

func (m *metricPostgresqlOperations) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, databaseAttributeValue string, tableAttributeValue string, operationAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Database, pdata.NewValueString(databaseAttributeValue))
	dp.Attributes().Insert(A.Table, pdata.NewValueString(tableAttributeValue))
	dp.Attributes().Insert(A.Operation, pdata.NewValueString(operationAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricPostgresqlOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricPostgresqlOperations) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricPostgresqlOperations(settings MetricSettings) metricPostgresqlOperations {
	m := metricPostgresqlOperations{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricPostgresqlRollbacks struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills postgresql.rollbacks metric with initial data.
func (m *metricPostgresqlRollbacks) init() {
	m.data.SetName("postgresql.rollbacks")
	m.data.SetDescription("The number of rollbacks.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

type MetricMetadataPostgresqlRollbacks struct{}

func (m MetricMetadataPostgresqlRollbacks) GetName() string {
	return "postgresql.rollbacks"
}

func (m MetricMetadataPostgresqlRollbacks) GetDescription() string {
	return "The number of rollbacks."
}

func (m MetricMetadataPostgresqlRollbacks) GetUnit() string {
	return "1"
}

func (m MetricMetadataPostgresqlRollbacks) GetValueType() string {
	return "int64"
}

func (m MetricMetadataPostgresqlRollbacks) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   true,
			ValueType:   "Int",
		},
	}
}

func (m *metricPostgresqlRollbacks) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, databaseAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Database, pdata.NewValueString(databaseAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricPostgresqlRollbacks) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricPostgresqlRollbacks) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricPostgresqlRollbacks(settings MetricSettings) metricPostgresqlRollbacks {
	m := metricPostgresqlRollbacks{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricPostgresqlRows struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills postgresql.rows metric with initial data.
func (m *metricPostgresqlRows) init() {
	m.data.SetName("postgresql.rows")
	m.data.SetDescription("The number of rows in the database.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

type MetricMetadataPostgresqlRows struct{}

func (m MetricMetadataPostgresqlRows) GetName() string {
	return "postgresql.rows"
}

func (m MetricMetadataPostgresqlRows) GetDescription() string {
	return "The number of rows in the database."
}

func (m MetricMetadataPostgresqlRows) GetUnit() string {
	return "1"
}

func (m MetricMetadataPostgresqlRows) GetValueType() string {
	return "int64"
}

func (m MetricMetadataPostgresqlRows) GetMetricType() MetricDataTypeMetadata {
	return MetricDataTypeMetadata{
		Sum: &Sum{
			Aggregation: pdata.MetricAggregationTemporalityCumulative,
			Monotonic:   false,
			ValueType:   "Int",
		},
	}
}

func (m *metricPostgresqlRows) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, databaseAttributeValue string, tableAttributeValue string, stateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Database, pdata.NewValueString(databaseAttributeValue))
	dp.Attributes().Insert(A.Table, pdata.NewValueString(tableAttributeValue))
	dp.Attributes().Insert(A.State, pdata.NewValueString(stateAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricPostgresqlRows) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricPostgresqlRows) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricPostgresqlRows(settings MetricSettings) metricPostgresqlRows {
	m := metricPostgresqlRows{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user settings.
type MetricsBuilder struct {
	startTime                  pdata.Timestamp // start time that will be applied to all recorded data points.
	metricsCapacity            int             // maximum observed number of metrics per resource.
	resourceCapacity           int             // maximum observed number of resource attributes.
	metricsBuffer              pdata.Metrics   // accumulates metrics data before emitting.
	metricPostgresqlBackends   metricPostgresqlBackends
	metricPostgresqlBlocksRead metricPostgresqlBlocksRead
	metricPostgresqlCommits    metricPostgresqlCommits
	metricPostgresqlDbSize     metricPostgresqlDbSize
	metricPostgresqlOperations metricPostgresqlOperations
	metricPostgresqlRollbacks  metricPostgresqlRollbacks
	metricPostgresqlRows       metricPostgresqlRows
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pdata.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(settings MetricsSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		startTime:                  pdata.NewTimestampFromTime(time.Now()),
		metricsBuffer:              pdata.NewMetrics(),
		metricPostgresqlBackends:   newMetricPostgresqlBackends(settings.PostgresqlBackends),
		metricPostgresqlBlocksRead: newMetricPostgresqlBlocksRead(settings.PostgresqlBlocksRead),
		metricPostgresqlCommits:    newMetricPostgresqlCommits(settings.PostgresqlCommits),
		metricPostgresqlDbSize:     newMetricPostgresqlDbSize(settings.PostgresqlDbSize),
		metricPostgresqlOperations: newMetricPostgresqlOperations(settings.PostgresqlOperations),
		metricPostgresqlRollbacks:  newMetricPostgresqlRollbacks(settings.PostgresqlRollbacks),
		metricPostgresqlRows:       newMetricPostgresqlRows(settings.PostgresqlRows),
	}
	for _, op := range options {
		op(mb)
	}
	return mb
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pdata.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
	if mb.resourceCapacity < rm.Resource().Attributes().Len() {
		mb.resourceCapacity = rm.Resource().Attributes().Len()
	}
}

// ResourceOption applies changes to provided resource.
type ResourceOption func(pdata.Resource)

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead. Resource attributes should be provided as ResourceOption arguments.
func (mb *MetricsBuilder) EmitForResource(ro ...ResourceOption) {
	rm := pdata.NewResourceMetrics()
	rm.Resource().Attributes().EnsureCapacity(mb.resourceCapacity)
	for _, op := range ro {
		op(rm.Resource())
	}
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName("otelcol/postgresqlreceiver")
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricPostgresqlBackends.emit(ils.Metrics())
	mb.metricPostgresqlBlocksRead.emit(ils.Metrics())
	mb.metricPostgresqlCommits.emit(ils.Metrics())
	mb.metricPostgresqlDbSize.emit(ils.Metrics())
	mb.metricPostgresqlOperations.emit(ils.Metrics())
	mb.metricPostgresqlRollbacks.emit(ils.Metrics())
	mb.metricPostgresqlRows.emit(ils.Metrics())
	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user settings, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(ro ...ResourceOption) pdata.Metrics {
	mb.EmitForResource(ro...)
	metrics := pdata.NewMetrics()
	mb.metricsBuffer.MoveTo(metrics)
	return metrics
}

// RecordPostgresqlBackendsDataPoint adds a data point to postgresql.backends metric.
func (mb *MetricsBuilder) RecordPostgresqlBackendsDataPoint(ts pdata.Timestamp, val int64, databaseAttributeValue string) {
	mb.metricPostgresqlBackends.recordDataPoint(mb.startTime, ts, val, databaseAttributeValue)
}

// RecordPostgresqlBlocksReadDataPoint adds a data point to postgresql.blocks_read metric.
func (mb *MetricsBuilder) RecordPostgresqlBlocksReadDataPoint(ts pdata.Timestamp, val int64, databaseAttributeValue string, tableAttributeValue string, sourceAttributeValue string) {
	mb.metricPostgresqlBlocksRead.recordDataPoint(mb.startTime, ts, val, databaseAttributeValue, tableAttributeValue, sourceAttributeValue)
}

// RecordPostgresqlCommitsDataPoint adds a data point to postgresql.commits metric.
func (mb *MetricsBuilder) RecordPostgresqlCommitsDataPoint(ts pdata.Timestamp, val int64, databaseAttributeValue string) {
	mb.metricPostgresqlCommits.recordDataPoint(mb.startTime, ts, val, databaseAttributeValue)
}

// RecordPostgresqlDbSizeDataPoint adds a data point to postgresql.db_size metric.
func (mb *MetricsBuilder) RecordPostgresqlDbSizeDataPoint(ts pdata.Timestamp, val int64, databaseAttributeValue string) {
	mb.metricPostgresqlDbSize.recordDataPoint(mb.startTime, ts, val, databaseAttributeValue)
}

// RecordPostgresqlOperationsDataPoint adds a data point to postgresql.operations metric.
func (mb *MetricsBuilder) RecordPostgresqlOperationsDataPoint(ts pdata.Timestamp, val int64, databaseAttributeValue string, tableAttributeValue string, operationAttributeValue string) {
	mb.metricPostgresqlOperations.recordDataPoint(mb.startTime, ts, val, databaseAttributeValue, tableAttributeValue, operationAttributeValue)
}

// RecordPostgresqlRollbacksDataPoint adds a data point to postgresql.rollbacks metric.
func (mb *MetricsBuilder) RecordPostgresqlRollbacksDataPoint(ts pdata.Timestamp, val int64, databaseAttributeValue string) {
	mb.metricPostgresqlRollbacks.recordDataPoint(mb.startTime, ts, val, databaseAttributeValue)
}

// RecordPostgresqlRowsDataPoint adds a data point to postgresql.rows metric.
func (mb *MetricsBuilder) RecordPostgresqlRowsDataPoint(ts pdata.Timestamp, val int64, databaseAttributeValue string, tableAttributeValue string, stateAttributeValue string) {
	mb.metricPostgresqlRows.recordDataPoint(mb.startTime, ts, val, databaseAttributeValue, tableAttributeValue, stateAttributeValue)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...metricBuilderOption) {
	mb.startTime = pdata.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(mb)
	}
}

func (mb *MetricsBuilder) Record(metricName string, ts pdata.Timestamp, value interface{}, attributes ...string) error {
	switch metricName {

	case "postgresql.backends":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordPostgresqlBackendsDataPoint(ts, intVal, attributes[0])
	case "postgresql.blocks_read":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordPostgresqlBlocksReadDataPoint(ts, intVal, attributes[0], attributes[1], attributes[2])
	case "postgresql.commits":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordPostgresqlCommitsDataPoint(ts, intVal, attributes[0])
	case "postgresql.db_size":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordPostgresqlDbSizeDataPoint(ts, intVal, attributes[0])
	case "postgresql.operations":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordPostgresqlOperationsDataPoint(ts, intVal, attributes[0], attributes[1], attributes[2])
	case "postgresql.rollbacks":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordPostgresqlRollbacksDataPoint(ts, intVal, attributes[0])
	case "postgresql.rows":
		intVal, ok := value.(int64)
		if !ok {
			return fmt.Errorf("invalid data point value")
		}
		mb.RecordPostgresqlRowsDataPoint(ts, intVal, attributes[0], attributes[1], attributes[2])
	}
	return nil
}

// Attributes contains the possible metric attributes that can be used.
var Attributes = struct {
	// Database (The name of the database.)
	Database string
	// Operation (The database operation.)
	Operation string
	// Source (The block read source type.)
	Source string
	// State (The tuple (row) state.)
	State string
	// Table (The schema name followed by the table name.)
	Table string
}{
	"database",
	"operation",
	"source",
	"state",
	"table",
}

var metricsByName = map[string]MetricIntf{
	"postgresql.backends":    MetricMetadataPostgresqlBackends{},
	"postgresql.blocks_read": MetricMetadataPostgresqlBlocksRead{},
	"postgresql.commits":     MetricMetadataPostgresqlCommits{},
	"postgresql.db_size":     MetricMetadataPostgresqlDbSize{},
	"postgresql.operations":  MetricMetadataPostgresqlOperations{},
	"postgresql.rollbacks":   MetricMetadataPostgresqlRollbacks{},
	"postgresql.rows":        MetricMetadataPostgresqlRows{},
}

func EnabledMetrics(settings MetricsSettings) map[string]bool {
	return map[string]bool{
		"postgresql.backends":    settings.PostgresqlBackends.Enabled,
		"postgresql.blocks_read": settings.PostgresqlBlocksRead.Enabled,
		"postgresql.commits":     settings.PostgresqlCommits.Enabled,
		"postgresql.db_size":     settings.PostgresqlDbSize.Enabled,
		"postgresql.operations":  settings.PostgresqlOperations.Enabled,
		"postgresql.rollbacks":   settings.PostgresqlRollbacks.Enabled,
		"postgresql.rows":        settings.PostgresqlRows.Enabled,
	}
}

func ByName(n string) MetricIntf {
	return metricsByName[n]
}

// A is an alias for Attributes.
var A = Attributes

// AttributeOperation are the possible values that the attribute "operation" can have.
var AttributeOperation = struct {
	Ins    string
	Upd    string
	Del    string
	HotUpd string
}{
	"ins",
	"upd",
	"del",
	"hot_upd",
}

// AttributeSource are the possible values that the attribute "source" can have.
var AttributeSource = struct {
	HeapRead  string
	HeapHit   string
	IdxRead   string
	IdxHit    string
	ToastRead string
	ToastHit  string
	TidxRead  string
	TidxHit   string
}{
	"heap_read",
	"heap_hit",
	"idx_read",
	"idx_hit",
	"toast_read",
	"toast_hit",
	"tidx_read",
	"tidx_hit",
}

// AttributeState are the possible values that the attribute "state" can have.
var AttributeState = struct {
	Dead string
	Live string
}{
	"dead",
	"live",
}
